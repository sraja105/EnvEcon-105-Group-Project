# -*- coding: utf-8 -*-
"""NEW_Final Group Project,_Anoushka Soni & Sofia Raja_ENVECON 105.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2sSfwPBTz7wQX0Wmgi6JWExSI83lOmT

### **Name: Anoushka Soni & Sofia Raja**
### ENVECON 105, Professor Xiangyi Meng
### August 2nd 2025  
### **Final Group Project**
"""

# Questions for Monday, August 11th: Can we have the same narrative (word for word) between our individual project and group project? Especially if they are doing the same thing

"""Instructions: _For your group, the project is a case study of data analytics for a chosen country’s CO2 emission. You are going to complete the analysis in a Jupyter Notebook and create and deploy a Dashboard for your work. For your individual project, you have been replicating the Bloomberg Open Case Study on CO2 Emissions Across Time for the world and the US. For this group project, you and your teammate must choose a non-USA COUNTRY and replicate what the case study (Exploring CO2 Emissions Across Time) has done using the USA data._

**Grading: Execution, Narrative, Creativity, Presentation, Extra Credit: Creativity and Insights**
"""

#Importing relevant libraries
#!pip install lets_plot
#!pip install openpyxl
#!pip install plotnine
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lets_plot import *
import warnings
from functools import reduce
from plotnine import ggplot, aes, geom_line
from statsmodels.nonparametric.smoothers_lowess import lowess
from sklearn.preprocessing import StandardScaler

warnings.simplefilter(action='ignore')

"""###**Selected Country: China**

### 1. Motivation (Anoushka)

**1) Why did you pick this country? (Anoushka)** <br>
Considering that our individual project allowed us to explore CO2 Emissions Across Time for the United States, choosing China as the country we are exploring CO2 Emissions Across Time for our group project will allow us to see differences in CO2 over time with two very powerful, but contrasting countries. From prior knowledge, we know that the U.S. and China are different in their economic development, transition into energy policy, and global significance, which all have an impact on their CO2 Emissions across time. We (Anoushka and Sofia) predict that the results we see from China's data will __.  <br>

**2) What are some facts about CO2 emissions for that country?** <br>
insert answer here <br>

### 2. Main Research Questions

**1) How has China’s CO2 emissions changed over time? And how  does China compare to other countries (the rest of the world)?**



**2) Are CO2 emissions, temperature, and natural disasters in China associated?**

### 3. Context (Sofia)

**1) What is the data? What does it measure? What does a given value for the variables of  interest mean?** <br>
insert answer here <br>
Insert information about our pathway to temperature here Just comment about why we chose the Temperature path we chose to collect the data.

Path for fetching temperature data set: Go into the website, go to filter by countries first, then select China, then cru-x0.5/CRU 0.5-degree, then timeseries, then, tas	Average Mean Surface Air Temperature, then selecting annual, and then selecting 1900-2024 as our time period, then mean as the percentile label, then historical as our scenario, and then cru as our model label, then ts4.09 as our model calculation label.

Here, for temperature, our variables of interest are 1) the year and 2) the value of the average temperature per year. This would mean that a given value for the main variable of interest would be the mean surface air temperature (abbreviated as tas on the website).


Common mistake for research is that we can't find the data for any explaination why we used this daata. Everything we do in a reseacrh project needs explaination. Just jsutfiy what we selected what we're doing . Explain that we couldnt find the data, when we measure it does it make sense to measure it

### 4. Limitations (Anoushka)

**1) What can you say using this data? What can you not say using this data? Provide a brief  discussion (3 to 4 sentences) for each question.** <br>
insert answer here <br>

### 5. What is the Data?
"""

#The table below is pulled from the individual project, still needs to be edited and filled in for the group project, dont need citation column

"""| Data                        | Time span   | Source                                                                 | Original Source                                                        | Description                                                                                              | Citation                                                                                                                                         |
|-----------------------------|------------|------------------------------------------------------------------------|------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|
| CO2 emissions               | Insert here | [Gapminder](https://www.gapminder.org/)                                | [Carbon Dioxide Information Analysis Center (CDIAC)](https://cdiac.ess-dive.lbl.gov/) | CO2 emissions in tonnes or metric tons (equivalent to approximately 2,204.6 pounds) per person by country | NA                                                                                                                                              |
| GDP per capita (percent yearly growth) | 1961–2024  | [World Bank Group](https://data.worldbank.org/indicator/NY.GDP.PCAP.KD.ZG?locations=CN-1W)                                | [World Bank](https://www.worldbank.org/)                               | Growth Domestic Product (which is an overall measure of the health of nation’s economy) per person by country | NA                                                                                                                                              |
| Energy use per person       | 1960–2015  | [Gapminder](https://www.gapminder.org/)                                | [World Bank](https://www.worldbank.org/)                               | Use of primary energy before transformation to other end-use fuels, by country                           | NA                                                                                                                                              |
| China Natural Disasters        | 1900–2025  | [Public EM-DAT](https://public.emdat.be/data) | [Public EM-DAT](https://public.emdat.be/) | China data about:<br>– Biological<br>– Climatological<br>– Extra-terrestrial<br>– Geophysical<br>– Hydrological<br>– Meteorological | NA |
| Temperature                 | 1895–2019  | [The National Oceanic and Atmospheric Administration (NOAA)](https://www.noaa.gov/) | [The National Oceanic and Atmospheric Administration (NOAA)](https://www.noaa.gov/) | US National yearly average temperature (in Fahrenheit) from 1895 to 2019                                 | NOAA National Centers for Environmental information, Climate at a Glance: National Time Series, published June 2020, retrieved on June 26, 2020 from [Link](https://www.ncdc.noaa.gov/cag/) |

Delete later: Anoushka: CO2, Energy, Temperature
Sofia: Disaster, GDP (UPDATED)

### 6. Data Import (Sofia)

We have created a GitHub Repository to store the raw data files that we gathered from the provided links on the instructions for CO2, Energy, GDP, Natural Disasters, and Temperature. We did this to organize our data and have a centralized place to access the correct data files. You can access our GitHub Repository here: https://github.com/sraja105/EnvEcon-105-Group-Project
"""

# Reading C02 Emissions File
CO2_emissions_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/CO2_Emissions_china.xlsx"
CO2_emissions = pd.read_excel(CO2_emissions_url, engine='openpyxl')
CO2_emissions.head()

"""Since the first two rows of the GDP data have a different number of columns than the subsequent rows, they should be set to header = 2 in pd.read_csv()."""

# Reading GDP File
gdp_growth_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/GDP%20China.csv"
gdp_growth = pd.read_csv(gdp_growth_url, header = 2)
gdp_growth.head()

"""Since the first two rows of the energy use data have a different number of columns than the subsequent rows, they should be set to header = 2 in pd.read_csv()."""

# Reading Energy Use File
energy_use_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Energy%20Use%20China.csv"
energy_use = pd.read_csv(energy_use_url, header = 2)
energy_use.head()

# Reading Disaster File (CHINA SPECIFIC)
china_disaster_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Natural%20Disasters%20China.xlsx"
china_disaster = pd.read_excel(china_disaster_url)
china_disaster.head()

# Reading Temperature File (CHINA SPECIFIC)
china_temperature_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Temperature%20-%20China.xlsx"
china_temperature = pd.read_excel(china_temperature_url)
china_temperature.head()

"""### 7. Data Wrangling

### _Yearly CO2 Emissions (Data Wrangling)_

First, let’s take a look at the CO2 data (CO2_emissions). We can use the .head function of the pandas package to see just the first rows of our data. We can specify how many rows we would like by putting this number in parentheses after .head

Unlike the Bloomberg Open Case study, we do not need to use the %>% pipe because pandas already supports method chaining natively.
"""

# Reading the CO2 Emissions data
CO2_emissions.head(3)

"""Another useful function is sample() to look at a selection of random rows using pseudorandom numbers for the index of rows to show. To continue to get the same random values or for others to get the same values, we need to set a seed first. We can do this with the np.random.seed() base function. We just specify a number with this function and that will allow us to get the same subset of values from the sample() function. If two different people ran this code (without np.random.seed()), they would each see a different subset of rows. For data exploration, this isn’t a huge deal, but if we’d like separate analysts running the same code to see the same output, we will use set.seed(). If we changed np.random.seed(123) to np.random.seed(321), we would obtain a different random sample of rows.

For python, the syntax for set.seed() would be different from the Bloomberg Open Case Study. In python, we use np.random.seed(123).
"""

np.random.seed(123) # set seed for reproducibility
CO2_emissions.sample(n=3)

"""Question Opportunity: Try setting a different seed to see the difference in the output.
Answer: Below, we can see how the output changes if we change the seed number
"""

np.random.seed(999)  # set seed for reproducibility
CO2_emissions.sample(n=3)

np.random.seed(321)  # set seed for reproducibility
CO2_emissions.sample(n=3)

## CHANGE THIS ANALYSIS FOR THE NEW CO2 DATA

"""**Our (Anoushka & Sofia's) Analysis**: We see each country is represented along one row and each column contains yearly CO2 emissions. We also notice that there are few NA values, which is a good thing.

Similar to the Bloomberg Open Case Study, instead of using the glimpse() function of the dplyr package to view our data, we can use df.info() + df.head() of the pandas package, which is our closest built-in equivalent. This allows us to see all of our variables at once. We will see a tiny bit of each variable/column with the data displayed.
"""

#  structure: column names, non-null count, data types
CO2_emissions.info()
# first 5 rows for a quick peek
CO2_emissions.head()

"""Below, we can see that the data type for the data shown above is a data frame. We can check this by asking for the type()."""

# Checking for the data type
type(CO2_emissions)

"""For example, the country variable is made up of character values. In pandas, there’s no "character" type like in R — instead, text columns are stored as object dtype (or sometimes string in newer pandas versions if explicitly set)."""

# Finding the number of rows
CO2_emissions['country']

# Shows us amount of years (columns)
CO2_emissions.columns

"""We see that we have 192 rows different country variables and CO2 emission values for 264 different years (from 1751 to 2014).

Recall, the values are emissions in metric tons, also called tonnes. Scrolling through the info() function above, we can see that we have few NA values (which makes our data wrangling processes easier)

In this next code chunk, we’ll demonstrate how to update our CO2_emissions DataFrame in place instead of creating a separate object each time. In Python, we typically do this by reassigning back to the same variable (e.g., CO2_emissions = ...)

We’ll modify CO2_emissions to make it more usable for visualizations by reshaping it from wide format to long format. In pandas, we use the melt() function to do this.

Our goal is to collapse all the emissions values across different year columns into one new column called emission and create another column called Year to indicate which year each value came from. The id_vars argument tells pandas which columns we want to keep as identifiers (in this case, country stays as is). The value_vars argument (optional) lets us specify which columns to melt; if we don’t list them explicitly, pandas will melt everything except the id_vars.
"""

# Melting the CO2 emissions to be in long format
CO2_emissions_long = CO2_emissions.melt(id_vars = 'country', var_name = 'Year', value_name = 'Emissions')
np.random.seed(123)
CO2_emissions_long.sample(6)

#Determining number of total columns and rows for CO2_emissions
CO2_emissions_long.info()

## CHANGE THIS TO MATCH INDIVIDUAL PROJECT SINCE WE ARE NOW USING THAT DATASET

"""**Question Opportunity**

_Think a moment about what the dimensions of the CO2_emissions_long data frame are now and why? How would you check this?_
<br> **Answer**: The number of columns in the CO2_emissions_long data frame would just be 3, since we have country, year, and emissions as our columns. The rows would be 223 (the number of years between 1800 to 2022) multiplied by 194 (the total number of countries). We also have to keep in mind the fact that one column is fixed. This means that the number of rows CO2_emissions_long is 43262 rows (as shown above).

Let’s say we want to rename the country column so it’s capitalized. Similar to the Bloomberg Open Case Study, we can rename the column 'country' to be capitalized. In Python, we can do this with the rename() method in pandas. When renaming columns, the syntax is. Here, the old name goes first and the new name goes second.

You may also notice that the Year column is currently stored as text (object type in pandas). We want to convert it to a numeric type. To do this, we use the astype() method.

We can also create new variables or modify existing ones by assigning directly to a column name. For example, we’ll create a new column called Label and fill it with the value "CO2 Emissions (Metric Tons)" for every row:
"""

# Renaming, converting to numeric, and adding labels
CO2_emissions_long = CO2_emissions_long.rename(columns={'country': 'Country'})
CO2_emissions_long['Year'] = pd.to_numeric(CO2_emissions_long['Year'])
CO2_emissions_long['Label'] = "CO2 Emissions (Metric Tons)"
np.random.seed(123)
CO2_emissions_long.sample(6)

# Check information of the dataframe
CO2_emissions_long.info()

"""Great, we can see that now the Year variable is an integer (abbreviated int64), which is a numeric class.

Now, let’s take a look at the Country column to check if there’s anything unexpected. In Python, we use the .unique() method in pandas to view only the unique values in a column.

Finally, since pandas columns are already easily accessible, we can extract the values directly as a Series using bracket notation (e.g., CO2_emissions['Country']) - this works like R’s dollar sign syntax (e.g., CO2_emissions 'dollar sign' Country), as seen in the Bloomberg Open Case Study.
"""

# View all unique country names
CO2_emissions_long['Country'].unique()

"""These all look as expected!

### _Yearly Growth in GDP per Capita (Data Wrangling)_

Let’s take a look at the next dataset (gdp_growth) that we imported.
"""

# Take out irrelevant columns
gdp_growth_dropped = gdp_growth.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')

# We made the head 4 in order to see 3 entries for 3 different countries, as opposed to seeing 2 entries for 2 countries if we put the argument as 3
gdp_growth_dropped.head(3)

"""**Our (Anoushka & Sofia's) Analysis**: As seen above, it's interesting to notice the number of NaN values for some of the years. We can see that the number of NaN values is higher for our GDP data compared to our CO2 emissions data

How many rows and columns are there are there? We can easily check by using the .shape function, which evaluates the dimensions of an object (in the Bloomberg Open Case Study, the function that is used is dim() when using R)
"""

# Checking dimentions
gdp_growth_dropped.shape

"""Interesting, it’s 266 rows (as opposed to 43261 above). We will deal with this and other differences in the sets of countries a bit later on. There are also 66 columns with country name and a set of columns (the rest of the columns) corresponding to different years.

"""

# Checking columns
gdp_growth_dropped.columns

"""Yes, there are no other columns in this dataset! This is expected, which is a good sign to proceed. This is because, at the beggining of this section, we made sure to drop the irrelevant columns in the gdp dataframe, so it would not be an issue when melting the data. In this case, the columns that we dropped are Country Code, the Indicator Name, and the Indicator Code columns.

Next, we’ll use the melt() function from pandas to transform the data into long format, similar to what we did earlier.

We’ll also rename the country column to Country using the rename() method, and we’ll convert the Year column to a numeric type using .astype().
"""

# melt from wide to long
gdp_growth_long = gdp_growth_dropped.melt(id_vars='Country Name', var_name='Year', value_name='gdp_growth')

# rename 'country' column to 'Country'
gdp_growth_long = gdp_growth_long.rename(columns={'Country Name': 'Country'})

# convert Year to numeric
gdp_growth_long['Year'] = pd.to_numeric(gdp_growth_long['Year'], errors='coerce')

# add Label column
gdp_growth_long['Label'] = "GDP Growth/Capita (%)"

# rename gdp_growth column to GDP
gdp_growth_long = gdp_growth_long.rename(columns={'gdp_growth': 'GDP'})

# Seeing how our data has changed after wrangling
gdp_growth_long.head(6)

"""Now, lets check if all years have the same number of observations, and for any missing data"""

# Checking for missing data
gdp_growth_long['Year'].value_counts()

"""This looks great, we have 266 observations (countries) for each year

Next, lets check that all the values in the Country column are values that we would expect
"""

# Checking values
gdp_growth_long['Country'].unique()

"""**Our (Anoushka & Sofia's) Analysis**:We notice that some of the countries listed here are not typical country names, such as "Upper middle income", or "Middle East, North Africa, Afghanistan & Pakistan (IDA & IBRD)". We will now filter some of the countries out for only recognizable country name using the pycountry package:"""

#Filtering for only commonly identifiable country names:
#!pip install pycountry
import pycountry

# Get a set of official country names
valid_countries = {country.name for country in pycountry.countries}

# Optional: add common aliases f needed
valid_countries.update(["Bolivia", "Congo", "Iran", "Russia", "Syria", "Venezuela"])

# Filter DataFrame
gdp_growth_long = gdp_growth_long[gdp_growth_long['Country'].isin(valid_countries)]

# Checking values again, after filtering the countries
gdp_growth_long['Country'].unique()

"""Now this looks good!

### _Energy Use per Person (Data Wrangling)_

Now let’s take a look at the energy use per person data (energy_use) using .head() and .info(), similar to the way the Bloomberg Open Case Study uses slice_head() and glimpse() for R.
"""

# Take out irrelevant columns
energy_use_dropped = energy_use.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')

# See the data with the dropped columns
energy_use_dropped.head(3)

"""**Our (Anoushka & Sofia's) Analysis**: We can see here that there are quite a few NaN values for some years. A few countries don't even have any values for any of the years, which is important to keep in mind as we are progressing through our analysis."""

#Checking dataframe
energy_use_dropped.info()

"""Looks like we have 266 rows and 66 columns, where we have a country column and again a set of years. This would mean that we have 65 years, since the first column tells us the country name. To wrangle the energy_use data, we will again convert the data to long format, rename some variables, and change the Year data to be numeric."""

# Reshape from wide to long format
energy_use_long = energy_use_dropped.melt(id_vars='Country Name', var_name='Year', value_name='energy_use')

# Rename Country Name column to Country
energy_use_long = energy_use_long.rename(columns={'Country Name': 'Country'})

# Convert Year to numeric
energy_use_long['Year'] = pd.to_numeric(energy_use_long['Year'])

# Add Label column
energy_use_long['Label'] = "Energy Use (kg, oil-eq./capita)"

# Rename energy_use column to Energy
energy_use_long = energy_use_long.rename(columns={'energy_use': 'Energy'})

# Displaying a random sample of the data
np.random.seed(123)
energy_use_long.sample(3)

"""We can also see how our data has changed by seeing a random sample of the data (seen above), like previously done.


Now, we will check the Country variable (list of all the unique countries)
"""

# Checking the country variable
energy_use_long['Country'].unique()

"""**Our (Anoushka & Sofia's) Analysis**: Similar to the GDP data, we notice that some of the countries listed here are not typical country names. As we can see in the random data sample of the GDP data displayed above, "Least developed countries: UN classification" is one of many non-specific country names/titles. We will now filter some of the countries out for only recognizable country names using the pycountry package, similar to the way we did for the GDP data:"""

#Filtering for only commonly identifiable country names:
#!pip install pycountry

# Get a set of official country names
valid_countries = {country.name for country in pycountry.countries}

# Optional: add common aliases f needed and alternative names
valid_countries.update(["Bolivia", "Congo", "Iran", "Russia", "Syria", "Venezuela"])

# Filter DataFrame
energy_use_long = energy_use_long[energy_use_long['Country'].isin(valid_countries)]

# Checking values again, after filtering the countries
gdp_growth_long['Country'].unique()

"""Now this looks good after filtering for country names!

### _China Specific Data - Disasters and Temperature (Data Wrangling)_

Now we will take a look at the China data about disasters and temperature.

### _China Disasters (Data Wrangling)_
"""

# ADD IN NARRATIVE (DONE)
# FIX LAST CODING FOR ADDING IN THE YEARS (still need to choose)

"""First, we will consider the disasters that have occurred in China."""

# Reading the disasters data
china_disaster.head()

"""We are specifically interested in the Year and counting the number of diasters that occur per year (no matter the disaster type). This means that we must aggregate all of the disaster types and count the total number of disasters. The other columns give extra information about the disasters, such as the estimated economic reconstruction cost in billions of dollars. For this analysis, we will focus just on the number of disasters that occurred each year.

We will select our variables of interest by grouping the columns from the dataframe and .group() function with the like argument in the pandas package (which would be DisNo, in our case).

When selecting a column by its exact name (e.g., Year), we can just reference it directly without quotes inside a list if selecting multiple columns, or as a string if selecting a single column.

Next, we are going to wrangle the "Year" column (currently named "DisNo.") to match the rest of our dataframes. We need to first check that the character length of all the values are the same in the 'DisNo.' column, so that we are only left with the year for all the values when dropping characters.
"""

# Checking to see that the year column is all the same length, so that when we crop out the unnecessary (in the next few lines), this will only leave us with the year
china_disaster['DisNo.'].astype(str).str.len()

"""Great! All of the values in the 'DisNo.' column have the same number of characters, 13. We can go ahead and just get the first 4 characters."""

# Now that we know that the character count for the "DisNo" column is all uniform, we will now only keep the only the first four characters of the values in "DisNo" to be representative of the year values for our "Year" column

china_disaster['DisNo.'] = china_disaster['DisNo.'].astype(str).str[:4]
china_disaster.head()

# see narrative below, maybe there's a better way to word all of this? Used language from the case study

"""Now we want to create a new column that will be the sum of all the different types of disasters for each year.

To perform the sum for each year, we can use the .groupby() function for each year, and only look at the "Disaster_Type" column for our answer

We could then add the values from the count of Disaster_Type column to our china_diaster dataframe like so, adding a new column, which is equivalent to the yearly disasters table (we called this column, 'Disasters'). In pandas, adding a new column is as simple as assigning a Series to df['new_column'].

Due to the fact that every row in the previous dataframe is representative of a disaster in a particular year (keeping in mind, that there can be mutliple disasters per year, which would mean that we have mutliple rows with the same year), here we are counting the number of disasters (no matter the type) that have occured in the same year. In other words, we are just aggregating by or grouping by year.

Comparing this to the Bloomberg Case Open Study, we don’t need a special . notation like in R’s dplyr (the way that the Bloomberg Open Case Study shows). When creating a new column based on other columns, we can directly reference the existing dataframe. In this case, we’ll drop all the rest of the columns (except for the Year column), calculate the sum of disasters per year, and store it in a new column called Disasters.
"""

# Grouping by year (regardless of disaster type)
china_disaster_count = china_disaster.groupby('DisNo.').count()
china_disaster_count['Disasters'] = china_disaster_count['Disaster Type']
china_disaster_count

"""Great, now we are going to remove some of these columns and just keep the columns of interest by choosing the required columns from the dataframe (Year and Disaster).

We are also going to add a new column called Country to indicate that this data is from the China. Again, this will create a new column where every value is China.
"""

# Resetting the index so 'DisNo.' becomes a column again
china_disaster_count_reset = china_disaster_count.reset_index()
china_disaster_two = china_disaster_count_reset[['DisNo.', 'Disasters']].copy()

# Adding a new variable called country to indicate that this data is from China
china_disaster_two['Country'] = "China"

# Renaming 'DisNo.' to 'Year' for consistency with other dataframes
china_disaster_two = china_disaster_two.rename(columns={'DisNo.': 'Year'})

# Melting the data into long format to match other dataframes
china_disaster_long = china_disaster_two.melt(id_vars=['Year', 'Country'], var_name='Indicator', value_name='Value')

# Adding in a label column
china_disaster_long['Label'] = "Number of Disasters"
china_disaster_long.head(6)

"""**Anoushka & Sofia's Analysis:** We notice that the years in the "Year" column are not represented (ie, the first year that is shown in the dataframe is 1902, and the second year that is shown jumpt to 1905). This is because we only have years that have at least one disaster. However, keeping the dataframe like this creates missing data in our dataframe. Even though years such as 1903 and 1904 did not have any diasters, this data should still be represented in our dataframe. In order to not have any missing years or values, we will ensure that each year is represented. Years that did not have any disasters will have a value of 0. Otherwise, if we have years that aren't represented in some dataframes, this will affect how we merge all 5 data sets due to missing data.

EDIT: Add in thinking processes to actually not include every single year in our table

**Anoushka and Sofia's Analysis**: We can see that the number of disasters has increased as time goes on. When comparing the head and the tail for the number of disasters seen over time, the disaster count towards the beginning of the 1900s are a much smaller value (none or only one instance per year), versus in current years, where we are seeing multiple instances of natural disasters per year.

**Question Opportunity**

This dataset was slightly different from the other datasets and therefore required slightly different wrangling. Why was it necessary to exclude the Year variable from the .melt() function? What would happen if we did not exclude Year?

**Answer:**
In Python, when reshaping from wide to long format using pandas.melt(), we exclude the Year column by listing it in the id_vars argument. This tells pandas to keep Year as an identifier variable rather than unpivoting it into the variable/value columns.

If we didn’t exclude Year (i.e., if it wasn’t listed in id_vars), pandas would treat it as a value column and melt it into the “variable” column along with the other data columns.

### _China Temperature (Data Wrangling)_

Next, we consider the temperature in the China over time.
"""

# Just look over narrative with Sofia (added by Anoushka on 8/12)

china_temperature.head()

"""**Our (Anoushka & Sofia's) Analysis**: When we first looked at the values of the temperatures as seen in the dataframe above for the yearly temperates of China since the 1900's, we had to inspect the data and interpret the appropriate units for which the data is in, as we are not familiar with the relative context of the expected average temperatures in China. As such, we cross checked some of the values for the most recent years with research online regarding average yearly temperatures in China. In other words, we verified that the data we are fetching is actually representative of other sources that tell us the average temperatures of China online.

First, to wrangle the temperature data, we want to melt the china_temperature dataframe to long format in order to make each row represent a specific year.

Then, we also want to create a Country column. We will also change the name of the Date column to Year so that it will be consistent with our other datasets. We can accomplish renaming here by using the .rename() function in pandas.

We also want to create an Indicator variable so that we can later tell what data the values in this dataframe represent if we combine it with other dataframes and a Label variable, so that we will have informative labels if we make a plot with this data later.

Finally, we change the label of the Date column to Year and also order the columns just like the other us data.
"""

# Melt the china_temperature DataFrame to long format, we do this first to make sure the years were on the rows instead of a column
china_temperature_long = china_temperature.melt(id_vars=['code', 'name'], var_name='Year', value_name='Value')
china_temperature_long['Indicator'] = "Temperature"
china_temperature_long['Label'] = "Temperature (Celcius)"

# Reorder the columns
china_temperature_long = china_temperature_long[['Year', 'name', 'Indicator', 'Value', 'Label']]
china_temperature_long = china_temperature_long.rename(columns = {'name': 'Country'})

# Checking for the first and last few lines of our data
china_temperature_long.head()
china_temperature_long.tail()

"""A few things need to be fixed here.

First, the Date column looks a bit strange. The format of the numbers look like the year followed by the characters, '-07'.

We want to change this to only keep the first 4 characters in the Date column string values.

However, first let’s make sure that indeed all of the Date values are 7 characters long and that they all end with the characters '-07'.

We can use a couple of functions in the pandas package to do this. The astype(str).str.len() combination of functions can be used to check the length of each value, while the astype(str).str.endswith combination of functions can be used to check that all the values end with "-07".

Let’s start with the astype(str).str.len() combination of functions to check for the length of the date values.
"""

# Checking to see that the year column is all the same length, so that when we crop out the month (in the next few lines), this will only leave us with the year
china_temperature_long['Year'].astype(str).str.len()

"""Great! It looks like all of the values are 7 characters long.

Now let’s check that they all end with "-07". We just need to specify what pattern to look for.
"""

# Checking that the unnecessary data that we have is all uniform, so that we can just keep the year
china_temperature_long['Year'].astype(str).str.endswith("-07")

"""Great! Since all of the values are True we know that all of the values in the Year column end with "-07".

It’s a good idea to always check that your data is as you expect.

Now we can use the .astype(str) function of the pandas package to remove the "-07" from each Year value.

We just need to indicate the start and stop characters.

In this case the start would be 1 and the 4th character would be where we want to stop, so we would use start = 0, stop = 4. We can do this inside of the .astype(str).str[:4] function to modify the Year column.

We also want the Year to be numeric. We can accomplish changing to numeric by using the .to_numeric function in the pandas package.
"""

# Using only the first four characters from the year column (and dropping the last three), as the first four characters only are representative of the Year and it will match the formatting of all of the other data sets
china_temperature_long['Year'] = china_temperature_long['Year'].astype(str).str[:4]

# Changing the 'Year' column to numeric
china_temperature_long['Year'] = pd.to_numeric(china_temperature_long['Year'])
china_temperature_long.head(6)

"""This looks great! It matches the dataframes we have previously made.

### _Joining Data_
"""

# Need to edit narrative, add pictures and question opportunities

"""Now that we have wrangled the individual datasets, we are ready to put everything together. Specifically, we will join the individual datasets into one using pd.merge() function.

Before we begin though, we will need to make sure that there is at least one variable/column that has the same name across all datasets to be joined. Such variables with common names are called keys for joining your data.

These are the by="x1" arguments below where x1 is the name of the column in both the a and b datasets that we will join together.

![image.png](attachment:92a7a12d-4759-46fa-b45a-af604122b18f.png)![image.png](attachment:c4ae9a40-d49b-419b-93a6-5b5765afe0f8.png)

First, we check using the .describe() function that there are column names that are consistent in each dataset that we wish to combine. Using the argument include = 'all' ensures that .describe() will apply to all, not just the numeric columns.
"""

# Check for consistent columns in each dataset
CO2_emissions_long.describe(include = 'all')

# Check for consistent columns in each dataset
gdp_growth_long.describe(include = 'all')

# Check for consistent columns in each dataset
energy_use_long.describe(include = 'all')

"""The Country, and Year variables are present in all of the datasets with values that overlap. Although Label is also present in the datasets, the values do not overlap. We can see that the minimum and maximum year is different for nearly all the datasets.

Next, we need to specify what columns/variables we will be joining by using the on = argument in the .merge() function.
"""

# Join the datasets using Country, Year, and Label
data_wide = pd.merge(CO2_emissions_long, gdp_growth_long, on = ['Country', 'Year', 'Label'], how = 'outer')
data_wide = pd.merge(data_wide, energy_use_long, on = ['Country', 'Year', 'Label'], how = 'outer')
np.random.seed(123)
data_wide.sample(6)

# Checking new data_wide dataframe
data_wide.info()
data_wide.head()

"""Nice, looks good!

We will also make a long version of this data, where we will create an new variable called Indicator that will indicate what dataset the data came from.
"""

# Create long version of the joined data and create Indicator variable
data_long = data_wide.melt(id_vars = ['Country', 'Year', 'Label'], var_name = 'Indicator', value_name = 'Value')

# View a random sample of 6 countries
np.random.seed(123)
data_long.sample(6)

"""We will now combine this data with the US data about disasters and temperatures."""

# View China disasters data
china_disaster_long.head(6)

# View China temperature data
china_temperature_long.head(6)

"""We will now use the pd.concat() function to combine the us_temperature data and the us_disaster data after the data_long data. Country is also converted to categorical type."""

# Join the China specific data to data_long
data_long = pd.concat([data_long, china_disaster_long, china_temperature_long], ignore_index = True)
data_long['Country'] = data_long['Country'].astype('category')

"""We can check the top and bottom of the new data_long to see that the us_temperature data is at the bottom. To see the end of data_long we can use .tail() function."""

# Check the top of the data_long dataset using .head()
data_long.head(6)

# Check the bottom of the data_long dataset using .tail()
data_long.tail(6)

# Check if the labels match the indicators
# Check a random set of 10 countries
np.random.seed(123)
data_long.sample(10)

"""We have a few more things to do before we leave the data wrangling section.

We will create a new variable called Region that will indicate if the data is about China or a different country based on the values in the Country variable. To do this, we will use the np.where() function.
"""

# Create Region variable
data_long['Region'] = np.where(data_long['Country'] == "China", "China", "Rest of the World")

# View the top of the data, sorted by country
data_long.sort_values(by = 'Country').head(6)

"""We can also remove rows for countries with NaN values using the .dropna() function to drop all years with missing data."""

# Remove rows with NaN values
data_long_sort = data_long.sort_values(by = 'Country')
data_long = data_long.dropna().sort_values(by = 'Country')
data_long.head(6)

# Seeing a random sample of rows to check for reasonability (check for indicators being matched with labels again)
np.random.seed(164)
data_long.sample(10)

"""### 8. Data Visualization

Instructions: (delete later):
**1) The first line plot under the "adding color" subsection.** <br>
insert answer here <br>

Finish this before the meeting on Wednesday (8/13) evening

**2) The top 10 emitting country line plot with names attached to the lines at the end  of the  "adding color" subsection.** <br>
insert answer here <br>
**3) The tile plot of the top 10 countries.** <br>
insert answer here <br>
**4) The last facet figure, 3x2 figure that shows all of the world and then just the  chosen country.** <br>
insert answer here <br>
**5) Recreate the two scatter plots in the “Scatter Plot” subsection, including the  trend lines on the figures.** <br>
insert answer here <br>

### _1) The first line plot under the "adding color" subsection (and the previous sections)._

In order to create the line plot that's seen under the "adding color" subsection, we need to create a framework for the graph first. The first step to do this would be to sum the emissions across countries for each year. Here, we use the .group_by() and .agg() function that we previously learned about.
"""

# Convert 'Value' to numeric, coercing errors to NaN
data_long['Value'] = pd.to_numeric(data_long['Value'], errors='coerce')

data_melted_all_region_filtered = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)
    .agg(Emissions=('Value', 'sum'))
)

data_melted_all_region_filtered.head()

"""Next, lets plot the CO2 emissions over time. Because our dataset contains other variables, we first need to filter our data to only include the CO2 emissions data by using the .groupby and .agg function of the pandas package. To use this function we need to specify what value (Emissions) we want for a given variable or column (Indicator).

In this case, we filter to keep all rows where the Indicator variable is equal to the word Emissions.

Then, we use the plt.plot() function (from the matplotlib package) to define that our x-axis will be the Year column and the y-axis will be the emissions Value column. If we want to plot separate lines for different countries, we can filter or group the data by the Country column and call plt.plot() for each group.

Here, we use the linewidth argument in plt.plot() to control the thickness of the lines.
"""

# Filtering to only include CO2 emissions data
data_melted_all_region_filtered = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)
    .agg(Emissions=('Value', 'sum'))
)

# Plot the graph
plt.figure(figsize=(10, 6))
plt.plot(
    data_melted_all_region_filtered['Year'],
    data_melted_all_region_filtered['Emissions'],
    linewidth=1.5,
    color='black'
)

# Show the plot
plt.show()

"""Wow, the CO₂ is really rising sharply! Next, we need to create the labels of the graph.

To change the title, caption, and axis labels in Python using matplotlib, we use the plt.title(), plt.xlabel(), and plt.ylabel() functions. Unlike plotnine/ggplot, where a plus sign (+) is used between layers, in matplotlib we directly call these functions after plotting the data (similar to the way the Bloomberg Open Case Study did by using R).

To display CO₂ with the "₂" subscript, we can write "CO₂" directly in the string by using the Unicode subscript character. For captions, matplotlib does not have a built-in caption parameter, so we use plt.figtext() to manually position the caption text anywhere on the figure—in this case, at the bottom-right corner.
"""

# Check the data range of data_melted_all_region_filtered
print(data_melted_all_region_filtered.head(1))
print(data_melted_all_region_filtered.tail(1))

"""INSERT TEXT HERE ABOUT DATE RANGE"""

# Filter & aggregate emissions data
emissions_summary = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)['Value']
    .sum()
    .rename(columns={'Value': 'Emissions'})
)

# Create the plot
plt.figure(figsize=(10, 6))
plt.plot(emissions_summary['Year'], emissions_summary['Emissions'], linewidth=1.5, color='black')

# Titles and labels
plt.title("World CO$_2$ Emissions per Year (1751-2014)")
plt.xlabel("Year")
plt.ylabel("Emissions (Metric Tonnes)")

# Caption (positioned manually at bottom-right)
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=9)

# Display the plot
plt.show()

"""Next, we can change the theme of the graph to make it look nicer, similar to the way the Bloomberg Open Case Study did. In Python with matplotlib, we adjust font sizes for the x-axis, y-axis, axis titles, and caption by passing the fontsize parameter to functions like plt.xlabel(), plt.ylabel(), and plt.title().

We can also customize tick label font sizes using plt.xticks(fontsize=...) and plt.yticks(fontsize=...). For captions, since matplotlib doesn’t have a built-in caption parameter, we can use plt.figtext() and specify the fontsize there.

In addition, while theme() in R’s ggplot2 changes many visual aspects of the plot, in matplotlib we achieve this through direct function arguments or style settings. For example, we can apply predefined styles like plt.style.use('seaborn-v0_8-whitegrid') or plt.style.use('classic') to modify the look of the entire plot
"""

# Filter & aggregate data
emissions_summary = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)['Value']
    .sum()
    .rename(columns={'Value': 'Emissions'})
)

# Create the plot
plt.style.use('seaborn-v0_8-whitegrid')  # similar to theme_linedraw()
plt.figure(figsize=(10, 6))
plt.plot(emissions_summary['Year'], emissions_summary['Emissions'], linewidth=1.5, color='black')

# Titles and labels with font sizes
plt.title("World CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
plt.xlabel("Year", fontsize=12)
plt.ylabel("Emissions (Metric Tonnes)", fontsize=12)

# Tick label sizes
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Caption
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

plt.show()

"""Great! We’ve created our first plot. Before we leave this section, let’s save this theme so we do not have to keep typing the same code in future plots: We are going to create a theme so that we can save it and use it later. In this way, we can just add another layer to our plot with the my_theme we created with the specifications of the sizes of the title and axis labels."""

# Define a reusable theme function
def my_theme():
    plt.style.use('seaborn-v0_8-whitegrid')  # Similar to theme_linedraw()
    plt.xticks(fontsize=12)                  # x-axis tick labels
    plt.yticks(fontsize=12)                  # y-axis tick labels
    # We’ll set axis titles, caption, and plot title in each plot individually

"""Let's add this theme to our plot:"""

# Summarize emissions by year
emissions_summary = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)['Value']
    .sum()
    .rename(columns={'Value': 'Emissions'})
)

# Create the figure (use the same name as the R object)
CO2_world, ax = plt.subplots(figsize=(10, 6))

# Apply your matplotlib "theme"
my_theme()

# Line plot
ax.plot(emissions_summary['Year'], emissions_summary['Emissions'],
        linewidth=1.5, color='black')

# Titles, labels, caption
ax.set_title("World CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Emissions (Metric Tonnes)", fontsize=12)
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

plt.show()

"""

Now, we can call our created graph by it's name, CO2_world!"""

CO2_world

# Filter data for only emissions
emissions_data = data_long[data_long['Indicator'] == 'Emissions']


emissions_data_sorted= data_long[data_long['Indicator'] == 'Emissions'].copy()
emissions_data_sorted['Year'] = pd.to_numeric(emissions_data_sorted['Year'], errors='coerce')
emissions_data_sorted.sort_values(['Country', 'Year'], inplace=True)

# Create the plot
plt.figure(figsize=(12, 6))
for country, group in emissions_data_sorted.groupby('Country'):
    plt.plot(group['Year'], group['Value'], color='black', linewidth=1)

# Labels and styling
plt.ylabel("Emissions", fontsize=12)
plt.xlabel("Year", fontsize=12)
plt.title("Country CO$_2$ Emissions per Year (1751-2014)", fontsize=16)

# Customizing ticks (similar to my_theme)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Show the plot
plt.show()

"""My (Anoushka's) Analysis: We can see that many countries show a dramatic increase in emissions over time with a handful of countries with particularly high levels. Since we have many overlapping lines, we will make our lines slightly transparent by using the alpha argument. This takes values from 0 to 1, where 0 is completely transparent and 1 is completely opaque. We also add our my_theme controlling the size of the title and axis labels."""

# Filter data for only emissions
emissions_data = data_long[data_long['Indicator'] == 'Emissions']

emissions_data_sorted = data_long[data_long['Indicator'] == 'Emissions'].copy()
emissions_data_sorted['Year'] = pd.to_numeric(emissions_data_sorted['Year'], errors='coerce')
emissions_data_sorted.sort_values(['Country', 'Year'], inplace=True)

# Create the plot
plt.figure(figsize=(12, 6))
for _, g in emissions_data_sorted.groupby('Country'):
    plt.plot(g['Year'], g['Value'], color='black', alpha=0.4, linewidth=0.7)

# Titles and labels
plt.title("Country CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
plt.xlabel("Year", fontsize=12)
plt.ylabel("Emissions (Metric Tonnes)", fontsize=12)

# Caption (manual positioning)
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

# Theme-like adjustments (equivalent to my_theme)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linewidth=0.5, alpha=0.5)

plt.show()

"""WE SEE SO MANY COUNTRIES!

**Adding Color** <br>
We can add another "layer" to our plot by drawing an additional blue line for just the U.S. data.
To do this in Python with matplotlib: First, plot all countries as usual. Then, filter the dataset to only include U.S. emissions. Plot this filtered line on top of the existing chart in blue. By default, matplotlib will choose its own color sequence, but here we explicitly set color='blue' to match our desired style. Blue is a good highlight color and is also more accessible to viewers with certain types of colorblindness compared to red. Instead of rewriting the base plot, we can simply call plt.plot() again on the filtered U.S. dataset to layer it on top of the existing lines.
"""

# Filter data for emissions only
emissions_data = data_long[data_long['Indicator'] == 'Emissions']

emissions_data_sorted= data_long[data_long['Indicator'] == 'Emissions'].copy()
emissions_data_sorted['Year'] = pd.to_numeric(emissions_data_sorted['Year'], errors='coerce')
emissions_data_sorted.sort_values(['Country', 'Year'], inplace=True)

# Base plot: All countries
plt.figure(figsize=(12, 6))
for _, g in emissions_data_sorted.groupby('Country'):
    plt.plot(g['Year'], g['Value'], color='black', alpha=0.4, linewidth=0.7)

# Overlay: China in blue
china_data = emissions_data_sorted[emissions_data_sorted['Country'] == 'China']
plt.plot(china_data['Year'], china_data['Value'], color='blue', linewidth=1.5, label = 'China')

# Titles and labels
plt.title("Country CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
plt.xlabel("Year", fontsize=12)
plt.ylabel("Emissions (Metric Tonnes)", fontsize=12)

# Caption
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

# Style adjustments (theme equivalent)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linewidth=0.5, alpha=0.5)
plt.legend(title = 'Country', loc = 'center left', bbox_to_anchor = (1, 0.5))
plt.show()

"""My (Anoushka's) Analysis: The graph above shows U.S. CO₂ emissions from 1751 to 2014 (blue) compared to other countries (gray). U.S. emissions began near zero in the late 18th century and rose sharply during the late 19th and early 20th centuries with industrialization. They accelerated further after World War II, reflecting economic expansion, suburban growth, and increased fossil fuel use, making the U.S. one of the world’s largest emitters. Emissions peaked in the early 2000s before declining, due in part to a shift from coal to natural gas, improvements in energy efficiency, growth in renewable energy, and outsourcing of manufacturing.

### _2) The top 10 emitting country line plot with names attached to the lines at the end of the "adding color" subsection_

Let’s figure out who are the top 10 emission producing countries in 2014. Here, we specify the data as the year 2014, which was the final year of the data. Then, we can make a rank variable based on the Value variable for the amount of emissions produced using the using .rank() function.

We want to do this in descending order because we want to rank by largest to smallest, so we will set the ascending argument = False in .rank().
"""

emissions_2014 = data_long[(data_long['Indicator'] == 'Emissions') & (data_long['Year'] == 2014)].copy()
emissions_2014['rank'] = emissions_2014['Value'].rank(method = 'dense', ascending = False)
top_10_count = emissions_2014[emissions_2014['rank'] <= 10].sort_values(by = 'rank')
top_10_count

"""We can see that China is now the top emission producing country.

Let’s make a plot of just these top ten countries.

To do this, we need to only keep countries in our Country variable that are also in the Country variable within top_10_count. Since we have 10 countries we will want to differentiate them by color.
"""

# Get the list of top 10 countries
top_10_countries_list = top_10_count['Country'].tolist()

# Ensure 'Year' column is numeric
data_long['Year'] = pd.to_numeric(data_long['Year'], errors='coerce')

# Only keep top 10 countries, Emissions, and Year >= 1900
top_10_emissions_data = data_long[
    (data_long['Country'].isin(top_10_countries_list)) &
    (data_long['Indicator'] == 'Emissions') &
    (data_long['Year'] >= 1900)
].copy()


# --- Order legend by emissions in 2014
order_2014 = (
    emissions_data_sorted[emissions_data_sorted['Year'] == 2014]
    .groupby('Country')['Value']
    .sum()
    .sort_values(ascending=False)
    .index
    .tolist()
)
# Handle countries missing 2014 data
others = [c for c in top_10_emissions_data if c not in order_2014]
legend_order = order_2014 + others



top_10_emissions_data = top_10_emissions_data.sort_values(by = 'Year')
Top10b, ax = plt.subplots(figsize = (12, 8))

for country, data in top_10_emissions_data.groupby('Country', observed = True):
    ax.plot(data['Year'], data['Value'], label = country, linewidth = 1.5)


# --- Labels, title, subtitle, legend
ax.set_title(
    "Top 10 Emissions-producing Countries in 2010 (1900-2014)\n"
    "Ordered by Emissions Produced in 2014",
    fontsize=16
)
ax.set_xlabel('Year')
ax.set_ylabel('Emissions (Metric Tonnes)')
plt.text(0.95, -0.1, 'Limited to reporting countries', ha = 'right', va = 'center',
         transform = plt.gca().transAxes, fontsize = 12)

# Legend in desired order — color the text to match the line
handles, labels = plt.gca().get_legend_handles_labels()
label_to_handle = {lab: h for lab, h in zip(labels, handles)}
ordered_handles = [label_to_handle[c] for c in legend_order if c in label_to_handle]


legend = plt.legend(
    ordered_handles,
    legend_order,
    title="Country",
    loc='upper left',
    bbox_to_anchor=(1.02, 1)
)

plt.show()

"""It’s still a bit difficult to tell which line corresponds to which country. So, let’s add a text label directly to the plot."""

#pip install adjustText

"""We need to indicate that our text label will be based on the Country variable.

We will also get rid of our legend since we will not need it anymore. To avoid the labels are overlapping making it difficult to read. We can adjust the text to avoid overlaps using adjust_text(texts, arrowprops = dict(arrowstyle = '-', color = 'gray', lw = 0.5)). You can see that adjust_text creates segments that connect the label to the line.

We can also expand the plot area horizontally so that the names are not cutoff by using plt.xlim(xmin, xmax + x_range * 0.3) to expand it by 30 percent.
"""

from adjustText import adjust_text

plt.figure(figsize = (12, 8))

lines = []
for country, data in top_10_emissions_data.groupby('Country', observed = True):
    line, = plt.plot(data['Year'], data['Value'], label = country, linewidth = 1.5)
    lines.append(line)

latest_year_data = top_10_emissions_data[top_10_emissions_data['Year'] == 2014]
texts = []

for line in lines:
    country = line.get_label()
    country_latest_data = latest_year_data[latest_year_data['Country'] == country]
    if not country_latest_data.empty:
        year = country_latest_data['Year'].iloc[0]
        value = country_latest_data['Value'].iloc[0]
        color = line.get_color()
        text = plt.text(year, value, country, fontsize=10, ha = 'left', va = 'center', color = color)
        texts.append(text)

# Expand the x-axis by 15% on the left and 30% on the right
xmin, xmax = plt.xlim()
x_range = xmax - xmin
plt.xlim(xmin - x_range * 0.15, xmax + x_range * 0.3)

# Adjust text to avoid overlaps
adjust_text(texts, arrowprops = dict(arrowstyle = '-', color = 'gray', lw = 0.5))


# --- Labels, title, subtitle, legend
plt.title(
    "Top 10 Emissions-producing Countries in 2010 (1900-2014)\n"
    "Ordered by Emissions Produced in 2014",
    fontsize=16
)
plt.xlabel('Year')
plt.ylabel('Emissions (Metric Tonnes)')
plt.text(0.95, -0.1, 'Limited to reporting countries', ha = 'right', va = 'center',
         transform = plt.gca().transAxes, fontsize = 12)
plt.show()

"""Nice, that looks pretty good. For fun, let’s try showing our data in an entirely different way."""

### SOFIA'S CODE ABOVE, ANOUSHKA'S BELOW





"""It looks like the US has long been the largest CO2 emission-producing country until recently, when the US was surpassed by another country. Below gives us a graph with a legend to know which line represents which country. The following graph shows the country names attached to each corresponding line.

**My (Anoushka's) Analysis**: This graph shows CO₂ emissions for the top 10 emitting countries in 2010, from 1900 to 2014, ordered by their 2014 emission levels. China’s emissions rose modestly until the late 20th century, then surged rapidly in the early 2000s, overtaking the United States as the largest emitter. The United States experienced steady growth in emissions throughout the 20th century, peaking in the early 2000s before showing a slight decline. India’s emissions have grown consistently, accelerating in recent decades, while countries like Russia, Japan, and Germany show peaks followed by stabilization or decline. This trend highlights the shift in global emissions leadership toward emerging economies, while some industrialized nations have begun reducing their outputs.

### _3) The tile plot of the top 10 countries._

This time we will create a geom_tile plot.

To create this plot we will filter our data to include only the Countries included in the Country variable of the top_10_count. First we will filter to the top 10 countries (from top_10_count['Country']), Indicator == "Emissions", and Year ≥ 1900. Next, we will rder countries by their last available emission value (i.e., the value at each country’s most recent year in the filtered data), matching fct_reorder(Country, Value, last).Finally, we will build a Year × Country matrix of log(Value) and draw it as a heatmap (tile plot) with a viridis continuous colormap.
"""

## SHOULD WE CHANGE THE YEAR RANGE TO MATCH THIS DATA INSTEAD

plt.style.use('default')  # clean white background (like theme_classic)

# --- Source and basic filtering
df0 = data_long.copy()
df0['Country'] = df0['Country'].astype(str).str.strip()
df0 = df0[df0['Indicator'] == 'Emissions'].copy()
df0['Year'] = pd.to_numeric(df0['Year'], errors='coerce')

# --- Top 10 by emissions in 2010 (to match your R workflow)
top_10_count = (
    df0[df0['Year'] == 2010]
    .groupby('Country')['Value'].sum()
    .nlargest(10)
    .reset_index()
)

top_countries = top_10_count['Country'].astype(str).str.strip().tolist()

# --- Keep only top 10 and Year >= 1900
df = df0[(df0['Country'].isin(top_countries)) & (df0['Year'] >= 1900)].copy()

# Safety checks (comment out once it works)
assert df['Country'].nunique() == 10, f"Expected 10 countries, got {df['Country'].nunique()}"
# print(sorted(df['Country'].unique()))

# --- Order countries by their *last* available value (like fct_reorder(..., last))
df.sort_values(['Country', 'Year'], inplace=True)
last_vals = df.groupby('Country')['Value'].last().sort_values(ascending=False)
ordered_countries = last_vals.index.tolist()

# --- Pivot to Year × Country and take log(Value)
df_pos = df.copy()
df_pos.loc[df_pos['Value'] <= 0, 'Value'] = np.nan  # avoid log(0)
heat = df_pos.pivot_table(index='Country', columns='Year', values='Value', aggfunc='sum')

# Reorder rows to match fct_reorder and sort columns by year
heat = heat.reindex(index=ordered_countries).sort_index(axis=1)
years = heat.columns.to_numpy(dtype=float)

heat_log = np.log(heat)

# --- Plot (geom_tile equivalent)
Top10TilePlot, ax = plt.subplots(figsize=(12, 6))
im = ax.imshow(
    heat_log.values,
    aspect='auto',
    cmap='viridis',
    interpolation='nearest'
)

# Y labels: the 10 countries in desired order
ax.set_yticks(range(len(ordered_countries)))
ax.set_yticklabels(ordered_countries, fontsize=12, color='black')

# X ticks: every 5 years from 1900 to 2022, only if present
desired_years = np.arange(1900, 2025, 5)
present_years = np.intersect1d(desired_years, years)
pos = [np.where(years == y)[0][0] for y in present_years] if years.size else []
ax.set_xticks(pos)
ax.set_xticklabels(present_years.astype(int), rotation=90, fontsize=12, color='black')

# Remove axis titles (to match axis.title = element_blank())
ax.set_xlabel('')
ax.set_ylabel('')

# Title + subtitle
ax.set_title("Top 10 CO₂ Emission-producing Countries\nOrdered by Emissions Produced in 2014", fontsize=16)

# Colorbar at bottom with label (scale_fill_viridis_c + labs(fill=...))
cbar = Top10TilePlot.colorbar(im, ax=ax, orientation='horizontal', fraction=0.08, pad=0.12)
cbar.set_label("Ln(CO₂ Emissions (Metric Tonnes))", fontsize=12)

plt.tight_layout()
plt.show()

"""**My (Anoushka's) Analysis**: This tile plot shows CO₂ emissions for the top 10
emitting countries in 2014, from 1900 to 2014, with color intensity representing the natural log of emissions in metric tonnes. China and the United States display consistently high emissions in recent decades, with China’s emissions intensifying sharply after 2000. India’s emissions have steadily increased, while countries like Russia, Japan, and Germany show high historical emissions that have plateaued or declined. Some countries, such as Saudi Arabia and South Korea, show relatively late but rapid growth in emissions starting in the mid-to-late 20th century. The gaps and lighter colors in earlier years reflect either lower emissions or missing historical data for certain countries.

### _4) The last facet figure, 3x2 figure_

In Python, we can create multiple small plots (“facets”) using matplotlib’s plt.subplots(...). This works much like facet_wrap() in R, allowing us to display several panels at once. To give each subplot its own y-axis scale, we simply avoid setting sharey=True when creating the subplots. If we want all panels to share the same y-axis, we can set sharey=True instead. Labels and titles for each panel are added with ax.set_title(...), while the overall title can be set with fig.suptitle(...).

Styling the facet labels, or “strips,” is also straightforward. We can change the font size and weight using the parameters in set_title(). If we want a bold strip on a colored bar, we can create it with a text box using ax.text(..., bbox=...). The layout of the facets—how many appear in each row or column—is controlled by the nrows and ncols arguments to plt.subplots(...), which is the equivalent of specifying rows and columns in facet_wrap().

When we want to facet by more than one variable, such as Indicator and Region to compare U.S. data with the rest of the world, we can create a grid of subplots where the rows correspond to one variable’s categories and the columns to the other’s. We then subset the data for each combination and draw the corresponding plot on the matching axes. This approach closely mirrors how facet_grid() works in R. If we want each row to have its own y-axis scale but still share it across columns in that row, we can create the subplots with sharex=True and control sharey at the row level rather than globally.

Finally, filtering the data before plotting works in Python much like it does in R. For example, if we want to exclude the “Disasters” and “Temperature” indicators because they are U.S.-only, we can use pandas boolean indexing with ~df['Indicator'].isin(['Disasters', 'Temperature']). This is the Python equivalent of R’s filter(!Indicator %in% c(...)).

This faceted graph is designed to compare trends in three key indicators—Emissions, Energy, and GDP—over time for two regions: the United States and the Rest of the World.
"""

# Prep
df = data_long.copy()
df = df[~df['Indicator'].isin(['Disasters', 'Temperature'])]  # like the R filter
df['Year'] = pd.to_numeric(df['Year'], errors='coerce')
df = df.dropna(subset=['Year', 'Value'])
df = df.sort_values(['Country', 'Year'])

# Desired facet order (adjust if your data uses other names)
row_keys = [k for k in ['Emissions', 'Energy', 'GDP'] if k in df['Indicator'].unique()]
col_keys = [k for k in ['Rest of the World', 'China'] if k in df['Region'].unique()]

nrows, ncols = len(row_keys), len(col_keys)
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10), sharex=True)

# Make axes indexable consistently
if nrows == 1 and ncols == 1:
    axes = [[axes]]
elif nrows == 1:
    axes = [axes]
elif ncols == 1:
    axes = [[ax] for ax in axes]

# Draw each facet
for i, ind in enumerate(row_keys):
    for j, reg in enumerate(col_keys):
        ax = axes[i][j]
        sub = df[(df['Indicator'] == ind) & (df['Region'] == reg)]
        for _, g in sub.groupby('Country'):
            ax.plot(g['Year'], g['Value'], color='black', linewidth=0.8)

        # y label only on left column
        if j == 0:
            ax.set_ylabel("Indicator Value", fontsize=11)
        else:
            ax.set_ylabel("")

        ax.grid(True, linewidth=0.5, alpha=0.5)
        ax.tick_params(labelsize=10)

# Column strip titles (top row)
for j, reg in enumerate(col_keys):
    axes[0][j].set_title(reg, fontsize=16, fontweight='bold')

# Row strip labels on the RIGHT (vertical black bars)
for i, ind in enumerate(row_keys):
    ax_right = axes[i][-1]
    ax_right.text(
        1.02, 0.5, ind,
        transform=ax_right.transAxes,
        rotation=-90, va='center', ha='left',
        fontsize=16, fontweight='bold', color='white',
        bbox=dict(boxstyle='square,pad=0.4', facecolor='black', edgecolor='black')
    )

# Overall title and bottom x label
fig.suptitle("Distribution of Indicators by Year and Value", fontsize=16, y=0.98)
for ax in axes[-1]:
    ax.set_xlabel("Year", fontsize=11)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""From these plots we can see that each type of data spans a different time span.

**My (Anoushka's) Analysis**: This set of six plots compares trends in emissions, energy use, and GDP growth between the United States and the rest of the world over time. For emissions, both the U.S. and the rest of the world show long-term increases, but U.S. emissions peaked around the early 2000s and have since declined, while global emissions—driven largely by other countries—continue to rise steeply. Energy use in the U.S. grew through much of the 20th century, peaking in the early 2000s before declining, whereas the rest of the world has seen steady and substantial growth in energy consumption. GDP growth patterns for the U.S. show more volatility during events like the Great Depression and post-war recovery, while global GDP growth is more dispersed across countries, with fluctuations tied to global economic shifts. Overall, the charts highlight how the U.S. historically led in emissions and energy use but has seen declines in recent decades, while the rest of the world has continued rapid growth.

### _5) Recreate the two scatter plots in the “Scatter Plot” subsection, including the trend lines on the figures._

Next, we’ll zoom in on two variables—CO₂ emissions and temperature—using only the years 1980–2014, since both series have data across that span. Because the datasets don’t cover identical time ranges, we’ll first filter with pandas so we keep only the overlapping years for both indicators.

We’ll then make a scatter plot with Matplotlib, treating Year as the x-axis and the indicator value as the y-axis. To show the underlying pattern, we’ll add a smoothed trend line on top of the points using a LOESS smoother from statsmodels.nonparametric.smoothers_lowess.lowess. LOESS is a local (nonparametric) regression: it fits many small least-squares models on neighborhoods of nearby points and stitches them together, so the line can curve with the data rather than forcing a single straight fit.
"""

## changing the name to CO2_temp_china_facet!!!!!!!!
# remember for the summary plot part

# ---- Filter to China, 1980–2014, and the two indicators
df = data_long.copy()
df['Year'] = pd.to_numeric(df['Year'], errors='coerce')

df = df[
    (df['Country'] == 'China') &
    (df['Year'] >= 1980) & (df['Year'] <= 2014) &
    (df['Indicator'].isin(['Emissions', 'Temperature']))
].dropna(subset=['Year', 'Value']).sort_values('Year')

# Facet by 'Label' like facet_wrap(Label ~ ., ncol = 1, scales='free_y')
labels = list(df['Label'].unique())
n = len(labels)

plt.style.use('classic')  # similar to theme_classic()
CO2_temp_china_facet, axes = plt.subplots(nrows=n, ncols=1, figsize=(10, 8), sharex=True)
if n == 1:
    axes = [axes]

labels = sorted(df['Label'].unique(), key=lambda x: 0 if 'CO2' in x or 'Emissions' in x else 1)


for ax, lab in zip(axes, labels):
    d = df[df['Label'] == lab].copy()

    # Scatter (geom_point)
    ax.scatter(d['Year'], d['Value'], s=20, color='black')

    # LOESS smoother (geom_smooth(method='loess', se=FALSE))
    # lowess expects sorted x
    d_sorted = d.sort_values('Year')
    sm = lowess(endog=d_sorted['Value'], exog=d_sorted['Year'], frac=0.3, it=0, return_sorted=True)
    ax.plot(sm[:, 0], sm[:, 1], color='royalblue', linewidth=2)

    # Panel (strip) title
    ax.set_title(lab, fontsize=14)

    # y-axis style
    ax.tick_params(labelsize=12)
    ax.set_ylabel("")   # axis.title blank like in your theme
    ax.grid(False)

# Common x settings: ticks every 5 years, rotated labels
xticks = np.arange(1980, 2020, 5)
axes[-1].set_xticks(xticks)
axes[-1].set_xticklabels(xticks, rotation=90, fontsize=12, color='black')
axes[-1].set_xlabel("")  # axis.title blank

# Overall title
CO2_temp_china_facet.suptitle("China Emissions and Temperatures (1980–2014)", fontsize=16, y=0.98)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""**My (Anoushka's) Analysis**: We can see that there are similar patterns of CO2 emission levels and average annual temperatures. In the top panel, CO₂ emissions rose steadily from the early 1980s through the early 2000s, peaking around 2005 at just under 6 million metric tons, before beginning a gradual decline. The bottom panel shows temperature fluctuations over the same period, with no perfectly consistent upward trend but a general rise from around 52°F in 1980 to slightly above 53°F in the 2000s. Both panels include a LOESS smoothing line, which highlights the mid-period increases and later leveling or decline. This suggests that while emissions began decreasing after the mid-2000s, temperatures did not show a corresponding immediate drop, reflecting the lagged and cumulative effects of greenhouse gases on climate. Overall, the plots illustrate the complex relationship between emissions and temperature, where reductions in emissions do not lead to instant climate stabilization.

Next, instead of looking at the variables separately in faceted plots, let’s look at the relationship between CO2 emissions and other variables directly. Now we can specify which indicators we want to look at, so now we can specifically look at emissions and temperature.
"""

# Convert 'Year' column to numeric before filtering
data_long['Year'] = pd.to_numeric(data_long['Year'], errors='coerce')

# Filter and pivot wider (like pivot_wider in R)
wide_china = (
    data_long[
        (data_long['Country'] == 'China') &
        (data_long['Year'] >= 1980) &
        (data_long['Year'] <= 2014)
    ]
    # remove Label column
    .drop(columns=['Label'])  # equivalent to select(-Label)
    .pivot(index='Year', columns='Indicator', values='Value')  # pivot_wider
    .reset_index()
)

# Plot Emissions vs Temperature
plt.style.use('classic')  # similar to theme_classic()

fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(
    wide_china['Emissions'],
    wide_china['Temperature'],
    color='black',
    s=40
)

# Styling similar to your R theme() call
ax.tick_params(axis='x', labelsize=12, colors='black')
ax.tick_params(axis='y', labelsize=12, colors='black')

ax.set_xlabel("Emissions (Metric Tonnes)", fontsize=14)
ax.set_ylabel("Temperature (Celcius)", fontsize=14) # Changed to Celcius based on data context
ax.set_title("China Emissions and Temperature (1980-2014)", fontsize=16)

ax.grid(False)

plt.tight_layout()
plt.show()

"""**My (Anoushka's) Analysis**: This scatter plot shows the relationship between U.S. CO₂ emissions (in metric tonnes) and average annual temperatures (in °F) from 1980 to 2014.

While there is no perfectly linear pattern, the data points suggest a generally positive relationship — higher emissions often correspond to higher temperatures. However, the spread of points indicates considerable variability, meaning that temperature is influenced by factors beyond just annual CO₂ emissions, such as natural climate variability, other greenhouse gases, and long-term accumulation effects. The lack of a tight clustering along a single line highlights that the connection between emissions and temperature is complex and not solely determined by year-to-year changes in emissions.

It might be helpful to add a trend line to this plot. In Python, we can do this using NumPy’s polyfit() function together with Matplotlib’s plot() function.

If we want to display a linear trend, we specify the degree of the polynomial as 1 in polyfit(). This fits a straight line to the data based on a simple linear regression model. The fitted line can then be drawn over the scatterplot using plot().

We can simply add this line of code to the existing Matplotlib plot to display a linear trend line alongside our data points.

The following scatterplot shows the relationship between CO₂ emissions (in metric tonnes) and average temperature (in Fahrenheit) in the United States between 1980 and 2014.
"""

# ---- Create scatter plot
plt.style.use('classic')
fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(
    wide_china['Emissions'],
    wide_china['Temperature'],
    color='black',
    s=30
)

# ---- Add linear regression line (equivalent to geom_smooth(method="lm"))
x = wide_china['Emissions']
y = wide_china['Temperature']
coef = np.polyfit(x, y, 1)  # degree 1 polynomial fit (linear)
poly1d_fn = np.poly1d(coef)
ax.plot(x, poly1d_fn(x), color='blue', linewidth=2)

# ---- Style like R theme()
ax.tick_params(axis='x', labelsize=9, colors='black')
ax.tick_params(axis='y', labelsize=9, colors='black')

ax.set_xlabel("Emissions (Metric Tonnes)", fontsize=14)
ax.set_ylabel("Temperature (Celcius)", fontsize=14)
ax.set_title("China Emissions and Temperature (1980-2014)", fontsize=16)

ax.grid(False)

plt.tight_layout()
plt.show()

"""**My (Anoushka's) Analysis**: Indeed, it does look like there is a positive, linear trend. Now that we see that there might be a linear relationship between CO2 emissions and temperature, let’s learn about some statistical techniques to measure the strength of that relationship.

### 9. Data Analysis
"""

# Adding in made during visualizations so i can start the analysis

# SHOULD WE DO THIS EARLIER? I DONT SEE IT AS A STEP IN INDIVIDUAL BUT I THINK WE NEED IT

# Convert the 'Year' column to numeric after concatenation
data_long['Year'] = pd.to_numeric(data_long['Year'])

# WE SHOULD CHECK IF 1980 - 2014 IS THE CORRECT RANGE FOR CHINA DATA

wide_china = (
    data_long[
        (data_long["Country"] == "China") &
        (data_long["Year"] >= 1980) &
        (data_long["Year"] <= 2014)
    ]
    # remove Label column
    .drop(columns = ["Label"])
    .pivot(index = "Year", columns = "Indicator", values = "Value")
    .reset_index()
)

# Convert the 'Emissions' and 'Temperature' columns to numeric, coercing errors to NaN
wide_china['Emissions'] = pd.to_numeric(wide_china['Emissions'], errors='coerce')
wide_china['Temperature'] = pd.to_numeric(wide_china['Temperature'], errors='coerce')


wide_china.head()

##  TAKE OUT THIS CODE CHUNK WHEN RESOLVE COMMENTS BC NOW HAVE IT IN VISUALIZATIONS

"""## 1) **Calculate the Mean and SD for emissions and temperature for your chosen country**

In this section, we are going to introduce some ways to better understand how two variables move together. We will focus on the CO2 emissions and temperature, but you will be encouraged to explore the relationship between CO2 emissions and the other variables.

#### Basic summary statistics
We can always calculate the sample mean and variance for two variables. Here, we can use .agg() to determine the mean and sd for emissions and temperature.
"""

# Calculate sample mean and standard deviation for CO2 emissions and temperature
wide_china.agg({
    "Emissions": ["mean", "std"],
    "Temperature": ["mean", "std"]
})

"""These are useful, but on their own they do not summarize whether or not there is a relationship between Emissions and Temperature (also these are on different scales entirely).

What else could we use? Next, we are going to learn about the correlation coefficient, which is a summary statistic that describes how two variables are related or move together.

## **2) Calculate the correlation coefficient for emissions and temperature**

We can use the correlation coefficient. Here, we are using this summary statistic to measure the strength of a linear relationship between two variables.

If we plot one variable on the x-axis and the other variable on the y-axis, we can see:

1. The strength of the relationship - based on how well the points form a line
2. The direction of the relationship - based on if the points progress upward or downward

If the variables point upward in a very clear line, then there is a strong positive relationship. If the points do not really form a line, then there is a weak linear relationship or no linear relationship. There may however be a nonlinear relationship if the points create a different but defined shape.

If the points form a downward sloping line, then there is a negative relationship.
![image.png](attachment:b23666bf-0b86-4536-abcc-807ba979ef31.png)

The numbers below each plot above are called correlation coefficients. They range from -1 to 1. A value of zero indicates that there is no correlation between the variables. While a value of 1 or -1 indicates perfect correlation, the closer the coefficient is to 1 or -1, the stronger the relationship. The sign of the coefficient indicates the direction of the relationship. If there is a negative relationship then the variables show opposing changes from each other - as one gets larger the other gets smaller. If the sign is positive, then the variables increase similarly.

Let’s calculate the Pearson’s correlation coefficient called “Rho” 𝜌
 between CO2 emissions and temperature in the US. There are a few ways to calculate a correlation coefficient and this is one of the most common.

Formally, if we have a pair of observations (𝑥1,𝑦1),…,(𝑥𝑛,𝑦𝑛), the correlation coefficient 𝜌 between 𝑥 and 𝑦 is defined as

![Screen Shot 2025-08-11 at 12.12.35 AM.png](attachment:d54cbd9f-d351-4db0-9b65-fac4727ca44f.png)

where 𝜇𝑥,𝜇𝑦 are the means of 𝑥1,…,𝑥𝑛 and 𝑦1,…,𝑦𝑛, respectively, and 𝜎𝑥,𝜎𝑦 are the standard deviations.

Therefore, we can standardize the two variables and essentially average (the denominator is n-1) the standardized values to calculate the correlation coefficient rho.

Here we will manually perform the calculation. We will use the len() function to get the number of samples 𝑛. In this case this is equivalent to the number of rows in wide_US.
"""

# Get the number of samples n
len(wide_china)

"""We will also use the np.sum function to standardize the Emissions and Temperature values."""

# Calculate the correlation coefficient for emissions and temperature method 1
rho = (1 / (len(wide_china) - 1)) * np.sum(
    ((wide_china['Emissions'] - wide_china['Emissions'].mean()) / wide_china['Emissions'].std()) *
    ((wide_china['Temperature'] - wide_china['Temperature'].mean()) / wide_china['Temperature'].std())
)
print(rho)

"""Alternatively, you can use the corr() function like so:"""

# Calculate the correlation coefficient for emissions and temperature method 2
r = wide_china['Emissions'].corr(wide_china['Temperature'])
print(r)

"""**(Our Analysis) The calculated correlation coefficient for emissions and temperature is 0.546988116710011**

<br>


To test if the association between a pair of variables is statistically significant, you can use pearsonr() to calculate the correlation coefficient, as well as confidence intervals for correlation coefficients.
"""

# Calculate the correlation coefficient and confidence intervals
from scipy.stats import pearsonr

r, p_value = pearsonr(wide_china['Emissions'], wide_china['Temperature'])

print(f"Pearson correlation: {r}")
print(f"P-value: {p_value}")

## ENSURE ACTUALLY SIGNIFICNAT BASED ON P-VALUE

"""We see that the correlation coefficient quantifying the strength of the linear relationship between C02 emissions and temperature is statistically significant since the p-value is 0.0006734053713994809.

( Analyze this further + maybe describe why)

## **3) Recreate the scaled scatter plot at the end "Relationship between correlation and linear regression" subsection**

Let’s briefly discuss the relationship between correlation and linear regression, which is further described in the Introduction to Data Science book.

We can use a regression line to predict a random variable 𝑌 given that we have gathered or observed some data about another variable 𝑋=𝑥. The regression line formally is defined as:

![Screen Shot 2025-08-11 at 12.25.45 AM.png](attachment:847d900a-643c-4ccb-8342-881fea3675ea.png)

where 𝜇𝑋 and 𝜎𝑋 (𝜇𝑌  and 𝜎𝑌) are the mean and standard deviation of 𝑋
 (𝑌), and 𝜌 is correlation between 𝑋 and 𝑌. If 𝑥 is larger than 𝜇𝑋, then for every 𝜎𝑋, then 𝑌 will also increase 𝜌 standard deviations above 𝜇𝑌.

Re-organizing the terms so that 𝑌
 is on the left side and everything else is on the right side, we get:

![Screen Shot 2025-08-11 at 12.26.27 AM.png](attachment:1443dc21-6c3b-4d9c-bafc-4aa4da6cb582.png)

Thinking about some extreme examples:

- If 𝜌 = 0 (i.e. no correlation), we ignore the 𝑥 term entirely and only predict 𝑌 using the mean 𝜇𝑌
- If 𝜌 = 1 (or -1) (i.e. perfect correlation), the regression line predicts an increase (or decrease) that is the same number of SDs.
- If 𝜌 is between -1 and 1, then we predict using both terms on the right hand side.

To add regression lines to plots, we will need the above formula in the form:
![Screen Shot 2025-08-11 at 12.27.19 AM.png](attachment:f072536c-3245-4c73-bbed-ac48ba4dbc8b.png)

In our example, we can calculate the slope and intercept using the formula above and plot the line. We need to first set variables equal to the summary statistics, then calculate the slope and intercept, then make the scatter plot and regression line based on these values.

**1) Calculate the Mean and SD for emissions and temperature for your chosen country** <br>
insert answer here <br>
**2) Calculate the correlation coefficient for emissions and temperature** <br>
insert answer here <br>
**3) Recreate the scaled scatter plot at the end "Relationship between correlation and  linear regression" subsection** <br>
insert answer here <br>

Add general synopsis for summary (narrative)
"""

# Determine summary statistics
mu_x = wide_china['Emissions'].mean()
sd_x = wide_china['Emissions'].std()
mu_y = wide_china['Temperature'].mean()
sd_y = wide_china['Temperature'].std()
rho = wide_china['Emissions'].corr(wide_china['Temperature'])

# Calculate slope and intercept
slope = rho * sd_y / sd_x
intercept = mu_y - slope * mu_x

fig, ax = plt.subplots(figsize = (10, 6))

# Scatterplot
ax.scatter(wide_china['Emissions'], wide_china['Temperature'], color = 'black', s = 20)
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

# Regression line using computed slope and intercept
x_vals = np.array(ax.get_xlim())
y_vals = intercept + slope * x_vals
ax.plot(x_vals, y_vals, color='black')

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.set_xlabel("Emissions", fontsize = 14)
ax.set_ylabel("Temperature", fontsize = 14)

plt.tight_layout()
plt.show()

"""Note: In the plot above, we use the scale of the original variables (CO2 emission and temperature), but the formula above implies that standardization of the variables (i.e. subtracting the mean and dividing by the standard deviation) allows the regression line to have an intercept of 0 and slope equal to 𝜌. A similar plot in standardized units is given below."""

import statsmodels.api as sm

# Standardize the variables similar to scale() in R
x = (wide_china['Emissions'] - wide_china['Emissions'].mean()) / wide_china['Emissions'].std()
y = (wide_china['Temperature'] - wide_china['Temperature'].mean()) / wide_china['Temperature'].std()

# Linear regression standardized so intercept of 0 and slope of p
X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

# Predicted values
y_pred = model.predict(X)

CO2_temp_china_scaled, ax = plt.subplots(figsize = (10, 6))

# Scatter plot
ax.scatter(x, y, color = 'black', alpha = 0.7)

# Regression line using new slope and intercept
ax.plot(x, y_pred, color = 'blue')
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

ax.set_title("China CO₂ Emissions and Temperature (1980–2014)")
ax.set_xlabel("Scaled Emissions (Metric Tonnes)", fontsize = 14)
ax.set_ylabel("Scaled Temperature (Celcius)", fontsize = 14)

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.show()

# Check that this figure is saved as CO2_temp_china_scaled
CO2_temp_china_scaled

"""# 7. Summary including the summary plot

## Summary Plot (Summary)


To summarize our findings in one figure, we can compose multiple plots into a single layout using Matplotlib using python. The closest analogue to patchwork’s plot_layout() is Matplotlib’s subplot mosaic (or GridSpec). We’ll build a 2×2 grid where the top row contains the CO2_world and Top10t plots, and the bottom row contains CO2_temp_US_facet and CO2_temp_US_scaled. We can control the relative widths and heights of rows/columns via width_ratios and height_ratios.

We did not save the graphs, instead we are calling the name of the graphs below to print all together in a mosaic format, similar to the Bloomberg Open Case Study.
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas

def fig_to_array(fig, dpi=300):
    """Render a Matplotlib Figure to an RGBA numpy array (no disk IO)."""
    orig_dpi = fig.get_dpi()
    fig.set_dpi(dpi)
    canvas = FigureCanvas(fig)
    canvas.draw()
    arr = np.asarray(canvas.buffer_rgba()).copy()
    fig.set_dpi(orig_dpi)
    return arr

# Convert your existing figures to arrays
img_co2_world        = fig_to_array(CO2_world)
img_top10_tile       = fig_to_array(Top10TilePlot)
img_us_facet         = fig_to_array(CO2_temp_china_facet)
img_us_scaled        = fig_to_array(CO2_temp_china_scaled)

# Create composite figure (no saving of individual plots)
fig = plt.figure(figsize=(14, 12))
gs = GridSpec(2, 2, figure=fig, width_ratios=[1, 2], height_ratios=[4, 10])

# Top row
ax1 = fig.add_subplot(gs[0, 0]); ax1.imshow(img_co2_world);  ax1.axis('off')
ax2 = fig.add_subplot(gs[0, 1]); ax2.imshow(img_top10_tile); ax2.axis('off')

# Bottom row
ax3 = fig.add_subplot(gs[1, 0]); ax3.imshow(img_us_facet);   ax3.axis('off')
ax4 = fig.add_subplot(gs[1, 1]); ax4.imshow(img_us_scaled);  ax4.axis('off')

plt.tight_layout()
plt.show()

"""My (Anoushka's) analysis of the overall Bloomberg Case Study: This case study examines the link between CO₂ emissions and temperature trends at global, national, and country-comparison levels. Globally, emissions have risen sharply since the Industrial Revolution, accelerating after the mid-20th century. A comparison of the top 10 emitting countries in 2014 shows China, the U.S., and India as leading contributors, with emerging economies rapidly increasing their output and some developed nations showing slower growth or decline. In the U.S., emissions peaked in the early 2000s and have since fallen, yet temperatures continue to rise, indicating lagged climate effects and the influence of global emissions. A correlation analysis between U.S. emissions and temperatures from 1980–2014 reveals a modest positive relationship, supporting the broader evidence that greenhouse gas emissions contribute to warming trends.

I've included my findings and analysis throught this jupyter notebook for each of the figures created, however, here is an analysis of the summary of all the graphs:

The charts collectively illustrate the relationship between CO₂ emissions and temperature trends from global to national scales. The first graph shows an exponential rise in worldwide CO₂ emissions from 1751 to 2014, with a sharp acceleration after the mid-20th century, reflecting industrial growth and fossil fuel dependence. The second chart, a heatmap of the top 10 CO₂-emitting countries ranked by 2014 emissions, highlights China, the United States, and India as dominant contributors, with emerging economies showing rapid increases while some developed nations’ emissions have plateaued or declined. The third set of U.S.-specific time-series plots reveals that national CO₂ emissions peaked in the early 2000s before declining, while average temperatures still trend upward despite short-term fluctuations, suggesting delayed climate responses and global influences. The final scatter plot quantifies this relationship, showing a modest but positive correlation between U.S. emissions and temperatures from 1980 to 2014, reinforcing the broader connection between greenhouse gas output and warming observed worldwide.
"""

## ADD IN SOME SORT OF SUMMARY/SYNOPSIS OF LEARNINGS FROM CASE STUDY