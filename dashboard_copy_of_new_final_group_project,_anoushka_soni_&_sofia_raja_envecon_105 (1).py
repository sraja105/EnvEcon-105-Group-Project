# -*- coding: utf-8 -*-
"""Dashboard_Copy of NEW_Final Group Project,_Anoushka Soni & Sofia Raja_ENVECON 105.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1squaCjFbytCQP3EECech4bRAJND8E9CI

### Name: Anoushka Soni & Sofia Raja
### ENVECON 105, Professor Xiangyi Meng
### August 2nd 2025  
### Final Group Project
"""

#Importing relevant libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lets_plot import *
import warnings
from functools import reduce
from plotnine import ggplot, aes, geom_line
from statsmodels.nonparametric.smoothers_lowess import lowess
from sklearn.preprocessing import StandardScaler

warnings.simplefilter(action='ignore')

"""### Name: Anoushka Soni & Sofia Raja
### ENVECON 105, Professor Xiangyi Meng
### August 2nd 2025  
### Final Group Project

### **Selected Country: China**

### Main Research Questions

**1) How has China’s CO2 emissions changed over time? And how  does China compare to other countries (the rest of the world)?**



**2) Are CO2 emissions, temperature, and natural disasters in China associated?**
"""

# Reading C02 Emissions File
CO2_emissions_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/CO2_Emissions_china.xlsx"
CO2_emissions = pd.read_excel(CO2_emissions_url, engine='openpyxl')
CO2_emissions.head()

# Reading GDP File
gdp_growth_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/GDP%20China.csv"
gdp_growth = pd.read_csv(gdp_growth_url, header = 2)
gdp_growth.head()

# Reading Energy Use File
energy_use_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Energy%20Use%20China.csv"
energy_use = pd.read_csv(energy_use_url, header = 2)
energy_use.head()

# Reading Disaster File (CHINA SPECIFIC)
china_disaster_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Natural%20Disasters%20China.xlsx"
china_disaster = pd.read_excel(china_disaster_url)
china_disaster.head()

# Reading Temperature File (CHINA SPECIFIC)
china_temperature_url = "https://raw.githubusercontent.com/sraja105/EnvEcon-105-Group-Project/main/Temperature%20-%20China.xlsx"
china_temperature = pd.read_excel(china_temperature_url)
china_temperature.head()

# Melting the CO2 emissions to be in long format
CO2_emissions_long = CO2_emissions.melt(id_vars = 'country', var_name = 'Year', value_name = 'Emissions')
np.random.seed(123)
CO2_emissions_long.sample(6)

# Renaming, converting to numeric, and adding labels
CO2_emissions_long = CO2_emissions_long.rename(columns={'country': 'Country'})
CO2_emissions_long['Year'] = pd.to_numeric(CO2_emissions_long['Year'])
CO2_emissions_long['Label'] = "CO2 Emissions (Metric Tons)"
np.random.seed(123)
CO2_emissions_long.sample(6)

# Take out irrelevant columns
gdp_growth_dropped = gdp_growth.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')

# melt from wide to long
gdp_growth_long = gdp_growth_dropped.melt(id_vars='Country Name', var_name='Year', value_name='gdp_growth')

# rename 'country' column to 'Country'
gdp_growth_long = gdp_growth_long.rename(columns={'Country Name': 'Country'})

# convert Year to numeric
gdp_growth_long['Year'] = pd.to_numeric(gdp_growth_long['Year'], errors='coerce')

# add Label column
gdp_growth_long['Label'] = "GDP Growth/Capita (%)"

# rename gdp_growth column to GDP
gdp_growth_long = gdp_growth_long.rename(columns={'gdp_growth': 'GDP'})

# Seeing how our data has changed after wrangling
gdp_growth_long.head(6)

#Filtering for only commonly identifiable country names:
import pycountry

# Get a set of official country names
valid_countries = {country.name for country in pycountry.countries}

# Optional: add common aliases f needed
valid_countries.update(["Bolivia", "Congo", "Iran", "Russia", "Syria", "Venezuela"])

# Filter DataFrame
gdp_growth_long = gdp_growth_long[gdp_growth_long['Country'].isin(valid_countries)]

# Take out irrelevant columns
energy_use_dropped = energy_use.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')

# Reshape from wide to long format
energy_use_long = energy_use_dropped.melt(id_vars='Country Name', var_name='Year', value_name='energy_use')

# Rename Country Name column to Country
energy_use_long = energy_use_long.rename(columns={'Country Name': 'Country'})

# Convert Year to numeric
energy_use_long['Year'] = pd.to_numeric(energy_use_long['Year'])

# Add Label column
energy_use_long['Label'] = "Energy Use (kg, oil-eq./capita)"

# Rename energy_use column to Energy
energy_use_long = energy_use_long.rename(columns={'energy_use': 'Energy'})

# Displaying a random sample of the data
np.random.seed(123)
energy_use_long.sample(3)

#Filtering for only commonly identifiable country names:

# Get a set of official country names
valid_countries = {country.name for country in pycountry.countries}

# Optional: add common aliases f needed and alternative names
valid_countries.update(["Bolivia", "Congo", "Iran", "Russia", "Syria", "Venezuela"])

# Filter DataFrame
energy_use_long = energy_use_long[energy_use_long['Country'].isin(valid_countries)]

# Now that we know that the character count for the "DisNo" column is all uniform, we will now only keep the only the first four characters of the values in "DisNo" to be representative of the year values for our "Year" column

china_disaster['DisNo.'] = china_disaster['DisNo.'].astype(str).str[:4]
china_disaster.head()

# Grouping by year (regardless of disaster type)
china_disaster_count = china_disaster.groupby('DisNo.').count()
china_disaster_count['Disasters'] = china_disaster_count['Disaster Type']

# Resetting the index so 'DisNo.' becomes a column again
china_disaster_count_reset = china_disaster_count.reset_index()
china_disaster_two = china_disaster_count_reset[['DisNo.', 'Disasters']].copy()

# Adding a new variable called country to indicate that this data is from China
china_disaster_two['Country'] = "China"

# Renaming 'DisNo.' to 'Year' for consistency with other dataframes
china_disaster_two = china_disaster_two.rename(columns={'DisNo.': 'Year'})

# Melting the data into long format to match other dataframes
china_disaster_long = china_disaster_two.melt(id_vars=['Year', 'Country'], var_name='Indicator', value_name='Value')

# Adding in a label column
china_disaster_long['Label'] = "Number of Disasters"
china_disaster_long.head(6)

# Melt the china_temperature DataFrame to long format, we do this first to make sure the years were on the rows instead of a column
china_temperature_long = china_temperature.melt(id_vars=['code', 'name'], var_name='Year', value_name='Value')
china_temperature_long['Indicator'] = "Temperature"
china_temperature_long['Label'] = "Temperature (Celcius)"

# Reorder the columns
china_temperature_long = china_temperature_long[['Year', 'name', 'Indicator', 'Value', 'Label']]
china_temperature_long = china_temperature_long.rename(columns = {'name': 'Country'})

# Checking for the first and last few lines of our data
china_temperature_long.head()
china_temperature_long.tail()

# Using only the first four characters from the year column (and dropping the last three), as the first four characters only are representative of the Year and it will match the formatting of all of the other data sets
china_temperature_long['Year'] = china_temperature_long['Year'].astype(str).str[:4]

# Changing the 'Year' column to numeric
china_temperature_long['Year'] = pd.to_numeric(china_temperature_long['Year'])
china_temperature_long.head(6)

# Join the datasets using Country, Year, and Label
data_wide = pd.merge(CO2_emissions_long, gdp_growth_long, on = ['Country', 'Year', 'Label'], how = 'outer')
data_wide = pd.merge(data_wide, energy_use_long, on = ['Country', 'Year', 'Label'], how = 'outer')
np.random.seed(123)
data_wide.sample(6)

# Create long version of the joined data and create Indicator variable
data_long = data_wide.melt(id_vars = ['Country', 'Year', 'Label'], var_name = 'Indicator', value_name = 'Value')

# View a random sample of 6 countries
np.random.seed(123)
data_long.sample(6)

# Join the China specific data to data_long
data_long = pd.concat([data_long, china_disaster_long, china_temperature_long], ignore_index = True)
data_long['Country'] = data_long['Country'].astype('category')

# Create Region variable
data_long['Region'] = np.where(data_long['Country'] == "China", "China", "Rest of the World")

# View the top of the data, sorted by country
data_long.sort_values(by = 'Country').head(6)

# Remove rows with NaN values
data_long_sort = data_long.sort_values(by = 'Country')
data_long = data_long.dropna().sort_values(by = 'Country')
data_long.head(6)

"""### Group Project: Data Visualization

# How has China's CO2 emissions changed over time?
"""

# Convert 'Value' to numeric, coercing errors to NaN
data_long['Value'] = pd.to_numeric(data_long['Value'], errors='coerce')

data_melted_all_region_filtered = (
    data_long[data_long['Indicator'] == 'Emissions']
    .groupby('Year', as_index=False)
    .agg(Emissions=('Value', 'sum'))
)

data_melted_all_region_filtered.head()

# Define a reusable theme function
def my_theme():
    plt.style.use('seaborn-v0_8-whitegrid')  # Similar to theme_linedraw()
    plt.xticks(fontsize=12)                  # x-axis tick labels
    plt.yticks(fontsize=12)                  # y-axis tick labels
    # We’ll set axis titles, caption, and plot title in each plot individually

# Filter data for emissions only
emissions_data = data_long[data_long['Indicator'] == 'Emissions']

emissions_data_sorted= data_long[data_long['Indicator'] == 'Emissions'].copy()
emissions_data_sorted['Year'] = pd.to_numeric(emissions_data_sorted['Year'], errors='coerce')
emissions_data_sorted.sort_values(['Country', 'Year'], inplace=True)

# Base plot: All countries
china_emissions_plot_blue, ax = plt.subplots(figsize=(12, 6))
for _, g in emissions_data_sorted.groupby('Country'):
    ax.plot(g['Year'], g['Value'], color='black', alpha=0.4, linewidth=0.7)

# Overlay: China in blue
china_data = emissions_data_sorted[emissions_data_sorted['Country'] == 'China']
ax.plot(china_data['Year'], china_data['Value'], color='blue', linewidth=1.5, label = 'China')

# Titles and labels
ax.set_title("Country CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Emissions (Metric Tonnes)", fontsize=12)

# Caption
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

# Style adjustments (theme equivalent)
ax.tick_params(axis='both', labelsize=12)
plt.yticks(fontsize=12)
ax.grid(True, linewidth=0.5, alpha=0.5)
ax.legend(title = 'Country', loc = 'center left', bbox_to_anchor = (1, 0.5))
plt.show()

china_emissions_plot_blue

"""SPACE FOR ANALYSIS

# Individual Project Insights: How does the United States's CO2 emission changes over time compare to China's?
"""

# Filter data for emissions only
emissions_data = data_long[data_long['Indicator'] == 'Emissions']

emissions_data_sorted= data_long[data_long['Indicator'] == 'Emissions'].copy()
emissions_data_sorted['Year'] = pd.to_numeric(emissions_data_sorted['Year'], errors='coerce')
emissions_data_sorted.sort_values(['Country', 'Year'], inplace=True)

# Base plot: All countries
US_emissions_plot_blue, ax = plt.subplots(figsize=(12, 6))
for _, g in emissions_data_sorted.groupby('Country'):
    ax.plot(g['Year'], g['Value'], color='black', alpha=0.4, linewidth=0.7)

# Overlay: United States in blue
US_data = emissions_data_sorted[emissions_data_sorted['Country'] == 'United States']
ax.plot(US_data['Year'], US_data['Value'], color='blue', linewidth=1.5, label = 'United States')

# Titles and labels
ax.set_title("Country CO$_2$ Emissions per Year (1751-2014)", fontsize=16)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Emissions (Metric Tonnes)", fontsize=12)

# Caption
plt.figtext(0.99, 0.01, "Limited to reporting countries", ha='right', fontsize=12)

# Style adjustments (theme equivalent)
ax.tick_params(axis='both', labelsize=12)
plt.yticks(fontsize=12)
ax.grid(True, linewidth=0.5, alpha=0.5)
ax.legend(title = 'Country', loc = 'center left', bbox_to_anchor = (1, 0.5))
plt.show()

US_emissions_plot_blue

"""SPACE FOR ANALYSIS

# How does China compare to other countries (the rest of the world), in terms of CO2 emissions?
"""

emissions_2014 = data_long[(data_long['Indicator'] == 'Emissions') & (data_long['Year'] == 2014)].copy()
emissions_2014['rank'] = emissions_2014['Value'].rank(method = 'dense', ascending = False)
top_10_count = emissions_2014[emissions_2014['rank'] <= 10].sort_values(by = 'rank')
top_10_count

"""SPACE FOR ANALYSIS ... CHINA IS RANKED #1 WITH 10300000.0 VALUE"""

from adjustText import adjust_text

# Get the list of top 10 countries
top_10_countries_list = top_10_count['Country'].tolist()

# Ensure 'Year' column is numeric
data_long['Year'] = pd.to_numeric(data_long['Year'], errors='coerce')

# Only keep top 10 countries, Emissions, and Year >= 1900
top_10_emissions_data = data_long[
    (data_long['Country'].isin(top_10_countries_list)) &
    (data_long['Indicator'] == 'Emissions') &
    (data_long['Year'] >= 1900)
].copy()

top_10_emissions_data = top_10_emissions_data.sort_values(by = 'Year')

# Create figure and axes
fig, ax = plt.subplots(figsize=(12, 8))

lines = []
for country, data in top_10_emissions_data.groupby('Country', observed=True):
    line, = ax.plot(data['Year'], data['Value'], label=country, linewidth=1.5)
    lines.append(line)

# Add text labels to the latest year data
latest_year_data = top_10_emissions_data[top_10_emissions_data['Year'] == 2014]
texts = []

for line in lines:
    country = line.get_label()
    country_latest_data = latest_year_data[latest_year_data['Country'] == country]
    if not country_latest_data.empty:
        year = country_latest_data['Year'].iloc[0]
        value = country_latest_data['Value'].iloc[0]
        color = line.get_color()
        text = ax.text(year, value, country, fontsize=10, ha='left', va='center', color=color)
        texts.append(text)

# Expand the x-axis by 15% on the left and 30% on the right
xmin, xmax = ax.get_xlim()
x_range = xmax - xmin
ax.set_xlim(xmin - x_range * 0.15, xmax + x_range * 0.3)

# Adjust text labels to avoid overlaps
adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5), ax=ax)

# --- Labels, title, subtitle, legend
ax.set_title(
    "Top 10 Emissions-producing Countries in 2014 (1900–2014)\n"
    "Ordered by Emissions Produced in 2014",
    fontsize=16
)
ax.set_xlabel('Year')
ax.set_ylabel('Emissions (Metric Tonnes)')
fig.text(0.95, 0.01, 'Limited to reporting countries', ha='right', va='center', fontsize=12)

# Save figure to a variable
top_10_emission = fig

top_10_emission

"""SPACE FOR ANALYSIS"""

plt.style.use('default')  # clean white background (like theme_classic)

# --- Source and basic filtering
df0 = data_long.copy()
df0['Country'] = df0['Country'].astype(str).str.strip()
df0 = df0[df0['Indicator'] == 'Emissions'].copy()
df0['Year'] = pd.to_numeric(df0['Year'], errors='coerce')

# --- Top 10 by emissions in 2010 (to match your R workflow)
top_10_count = (
    df0[df0['Year'] == 2010]
    .groupby('Country')['Value'].sum()
    .nlargest(10)
    .reset_index()
)

top_countries = top_10_count['Country'].astype(str).str.strip().tolist()

# --- Keep only top 10 and Year >= 1900
df = df0[(df0['Country'].isin(top_countries)) & (df0['Year'] >= 1900)].copy()

# Safety checks (comment out once it works)
assert df['Country'].nunique() == 10, f"Expected 10 countries, got {df['Country'].nunique()}"
# print(sorted(df['Country'].unique()))

# --- Order countries by their *last* available value (like fct_reorder(..., last))
df.sort_values(['Country', 'Year'], inplace=True)
last_vals = df.groupby('Country')['Value'].last().sort_values(ascending=False)
ordered_countries = last_vals.index.tolist()

# --- Pivot to Year × Country and take log(Value)
df_pos = df.copy()
df_pos.loc[df_pos['Value'] <= 0, 'Value'] = np.nan  # avoid log(0)
heat = df_pos.pivot_table(index='Country', columns='Year', values='Value', aggfunc='sum')

# Reorder rows to match fct_reorder and sort columns by year
heat = heat.reindex(index=ordered_countries).sort_index(axis=1)
years = heat.columns.to_numpy(dtype=float)

heat_log = np.log(heat)

# --- Plot (geom_tile equivalent)
Top10TilePlot, ax = plt.subplots(figsize=(12, 6))
im = ax.imshow(
    heat_log.values,
    aspect='auto',
    cmap='viridis',
    interpolation='nearest'
)

# Y labels: the 10 countries in desired order
ax.set_yticks(range(len(ordered_countries)))
ax.set_yticklabels(ordered_countries, fontsize=12, color='black')

# X ticks: every 5 years from 1900 to 2022, only if present
desired_years = np.arange(1900, 2025, 5)
present_years = np.intersect1d(desired_years, years)
pos = [np.where(years == y)[0][0] for y in present_years] if years.size else []
ax.set_xticks(pos)
ax.set_xticklabels(present_years.astype(int), rotation=90, fontsize=12, color='black')

# Remove axis titles (to match axis.title = element_blank())
ax.set_xlabel('')
ax.set_ylabel('')

# Title + subtitle
ax.set_title("Top 10 CO₂ Emission-producing Countries\nOrdered by Emissions Produced in 2014", fontsize=16)

# Colorbar at bottom with label (scale_fill_viridis_c + labs(fill=...))
cbar = Top10TilePlot.colorbar(im, ax=ax, orientation='horizontal', fraction=0.08, pad=0.12)
cbar.set_label("Ln(CO₂ Emissions (Metric Tonnes))", fontsize=12)

plt.tight_layout()
plt.show()

Top10TilePlot

"""SPACE FOR ANALYSIS"""

# Prep
df = data_long.copy()
df = df[~df['Indicator'].isin(['Disasters', 'Temperature'])]  # like the R filter
df['Year'] = pd.to_numeric(df['Year'], errors='coerce')
df = df.dropna(subset=['Year', 'Value'])
df = df.sort_values(['Country', 'Year'])

# Desired facet order (adjust if your data uses other names)
row_keys = [k for k in ['Emissions', 'Energy', 'GDP'] if k in df['Indicator'].unique()]
col_keys = [k for k in ['Rest of the World', 'China'] if k in df['Region'].unique()]

nrows, ncols = len(row_keys), len(col_keys)
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10), sharex=True)

# Make axes indexable consistently
if nrows == 1 and ncols == 1:
    axes = [[axes]]
elif nrows == 1:
    axes = [axes]
elif ncols == 1:
    axes = [[ax] for ax in axes]

# Draw each facet
for i, ind in enumerate(row_keys):
    for j, reg in enumerate(col_keys):
        ax = axes[i][j]
        sub = df[(df['Indicator'] == ind) & (df['Region'] == reg)]
        for _, g in sub.groupby('Country'):
            ax.plot(g['Year'], g['Value'], color='black', linewidth=0.8)

        # y label only on left column
        if j == 0:
            ax.set_ylabel("Indicator Value", fontsize=11)
        else:
            ax.set_ylabel("")

        ax.grid(True, linewidth=0.5, alpha=0.5)
        ax.tick_params(labelsize=10)

# Column strip titles (top row)
for j, reg in enumerate(col_keys):
    axes[0][j].set_title(reg, fontsize=16, fontweight='bold')

# Row strip labels on the RIGHT (vertical black bars)
for i, ind in enumerate(row_keys):
    ax_right = axes[i][-1]
    ax_right.text(
        1.02, 0.5, ind,
        transform=ax_right.transAxes,
        rotation=-90, va='center', ha='left',
        fontsize=16, fontweight='bold', color='white',
        bbox=dict(boxstyle='square,pad=0.4', facecolor='black', edgecolor='black')
    )

# Overall title and bottom x label
fig.suptitle("Distribution of Indicators by Year and Value", fontsize=16, y=0.98)
for ax in axes[-1]:
    ax.set_xlabel("Year", fontsize=11)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

china_facet_plot = fig

china_facet_plot

"""SPACE FOR ANALYSIS

# Individual Project Insights: Specifically, how does China compare to the United States?
"""

# Importing GDP Growth File
US_gdp_growth_url = "https://raw.githubusercontent.com/opencasestudies/ocs-bp-co2-emissions/master/data/raw/gdp_per_capita_yearly_growth.xlsx"
US_gdp_growth = pd.read_excel(US_gdp_growth_url, engine='openpyxl')

# Importing Energy Use File
US_energy_use_url = "https://raw.githubusercontent.com/opencasestudies/ocs-bp-co2-emissions/master/data/raw/energy_use_per_person.xlsx"
US_energy_use = pd.read_excel(US_energy_use_url, engine='openpyxl')

# Importing US Disasters File
us_disaster_url = "https://raw.githubusercontent.com/opencasestudies/ocs-bp-co2-emissions/master/data/raw/disasters.csv"
us_disaster = pd.read_csv(us_disaster_url, skiprows = 2)

# Importing US Temperature File
us_temperature_url = "https://raw.githubusercontent.com/opencasestudies/ocs-bp-co2-emissions/master/data/raw/temperature.csv"
us_temperature = pd.read_csv(us_temperature_url, skiprows = 4, na_values = "-99")

US_CO2_emissions_long = CO2_emissions.melt(id_vars = 'country', var_name = 'Year', value_name = 'Emissions')
US_CO2_emissions_long = US_CO2_emissions_long.rename(columns={'country': 'Country'})
US_CO2_emissions_long['Year'] = pd.to_numeric(US_CO2_emissions_long['Year'])
US_CO2_emissions_long['Label'] = "CO2 Emissions (Metric Tons)"

US_gdp_growth_long = US_gdp_growth.melt(id_vars = 'country', var_name = 'Year', value_name = 'gdp_growth')
US_gdp_growth_long = US_gdp_growth_long.rename(columns={'country': 'Country'})
US_gdp_growth_long['Year'] = pd.to_numeric(US_gdp_growth_long['Year'])
US_gdp_growth_long['Label'] = "GDP Growth/Capita (%)"
US_gdp_growth_long = US_gdp_growth_long.rename(columns={'gdp_growth': 'GDP'})

US_energy_use_long = US_energy_use.melt(id_vars='country', var_name='Year', value_name='energy_use')
US_energy_use_long = US_energy_use_long.rename(columns={'country': 'Country'})
US_energy_use_long['Year'] = pd.to_numeric(US_energy_use_long['Year'])
US_energy_use_long['Label'] = "Energy Use (kg, oil-eq./capita)"
US_energy_use_long = US_energy_use_long.rename(columns={'energy_use': 'Energy'})

us_disaster_count = us_disaster.filter(regex='Year|Count')
yearly_disasters = us_disaster.filter(regex='Count').sum(axis=1)
us_disaster['Disasters'] = yearly_disasters
us_disaster['Disasters'] = us_disaster.filter(regex='Count').sum(axis=1)
us_disaster_two = us_disaster[['Year', 'Disasters']].copy()
us_disaster_two['Country'] = "United States"
us_disaster_long = us_disaster_two.melt(id_vars=['Year', 'Country'], var_name='Indicator', value_name='Value')
us_disaster_long['Label'] = "Number of Disasters"

us_temperature['Date'] = us_temperature['Date'].astype(str).str[:4]
us_temperature_long = us_temperature.drop(columns=['Anomaly'])
us_temperature_long['Country'] = "United States"
us_temperature_long['Year'] = pd.to_numeric(us_temperature_long['Date'])
us_temperature_long['Indicator'] = "Temperature"
us_temperature_long['Label'] = "Temperature (Fahrenheit)"
us_temperature_long = us_temperature_long[['Year', 'Country', 'Indicator', 'Value', 'Label']]

data_wide = pd.merge(CO2_emissions_long, US_gdp_growth_long, on = ['Country', 'Year', 'Label'], how = 'outer')
data_wide = pd.merge(data_wide, US_energy_use_long, on = ['Country', 'Year', 'Label'], how = 'outer')
US_data_long = data_wide.melt(id_vars = ['Country', 'Year', 'Label'], var_name = 'Indicator', value_name = 'Value')
US_data_long = pd.concat([US_data_long, us_disaster_long, us_temperature_long], ignore_index = True)
US_data_long['Country'] = US_data_long['Country'].astype('category')
US_data_long['Region'] = np.where(US_data_long['Country'] == "United States", "United States", "Rest of the World")
US_data_long_sort = US_data_long.sort_values(by = 'Country')
US_data_long = US_data_long.dropna().sort_values(by = 'Country')

# Prep
df_US = US_data_long.copy()
df_US = df_US[~df_US['Indicator'].isin(['Disasters', 'Temperature'])]  # like the R filter
df_US['Year'] = pd.to_numeric(df_US['Year'], errors='coerce')
df_US = df_US.dropna(subset=['Year', 'Value'])
df_US = df_US.sort_values(['Country', 'Year'])

# Desired facet order (adjust if your data uses other names)
row_keys = [k for k in ['Emissions', 'Energy', 'GDP'] if k in df_US['Indicator'].unique()]
col_keys = [k for k in ['Rest of the World', 'United States'] if k in df_US['Region'].unique()]

nrows, ncols = len(row_keys), len(col_keys)
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10), sharex=True)

# Make axes indexable consistently
if nrows == 1 and ncols == 1:
    axes = [[axes]]
elif nrows == 1:
    axes = [axes]
elif ncols == 1:
    axes = [[ax] for ax in axes]

# Draw each facet
for i, ind in enumerate(row_keys):
    for j, reg in enumerate(col_keys):
        ax = axes[i][j]
        sub = df_US[(df_US['Indicator'] == ind) & (df_US['Region'] == reg)]
        for _, g in sub.groupby('Country'):
            ax.plot(g['Year'], g['Value'], color='black', linewidth=0.8)

        # y label only on left column
        if j == 0:
            ax.set_ylabel("Indicator Value", fontsize=11)
        else:
            ax.set_ylabel("")

        ax.grid(True, linewidth=0.5, alpha=0.5)
        ax.tick_params(labelsize=10)

# Column strip titles (top row)
for j, reg in enumerate(col_keys):
    axes[0][j].set_title(reg, fontsize=16, fontweight='bold')

# Row strip labels on the RIGHT (vertical black bars)
for i, ind in enumerate(row_keys):
    ax_right = axes[i][-1]
    ax_right.text(
        1.02, 0.5, ind,
        transform=ax_right.transAxes,
        rotation=-90, va='center', ha='left',
        fontsize=16, fontweight='bold', color='white',
        bbox=dict(boxstyle='square,pad=0.4', facecolor='black', edgecolor='black')
    )

# Overall title and bottom x label
fig.suptitle("Distribution of Indicators by Year and Value", fontsize=16, y=0.98)
for ax in axes[-1]:
    ax.set_xlabel("Year", fontsize=11)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

US_facet_plot = fig

US_facet_plot

"""SPACE FOR ANALYSIS

# Are CO2 emissions, temperature, and natural disasters in the China associated?
"""

# ---- Filter to China, 1980–2014, and the two indicators
df = data_long.copy()
df['Year'] = pd.to_numeric(df['Year'], errors='coerce')

df = df[
    (df['Country'] == 'China') &
    (df['Year'] >= 1980) & (df['Year'] <= 2014) &
    (df['Indicator'].isin(['Emissions', 'Temperature']))
].dropna(subset=['Year', 'Value']).sort_values('Year')

# Facet by 'Label' like facet_wrap(Label ~ ., ncol = 1, scales='free_y')
labels = list(df['Label'].unique())
n = len(labels)

plt.style.use('classic')  # similar to theme_classic()
CO2_temp_china_facet, axes = plt.subplots(nrows=n, ncols=1, figsize=(10, 8), sharex=True)
if n == 1:
    axes = [axes]

labels = sorted(df['Label'].unique(), key=lambda x: 0 if 'CO2' in x or 'Emissions' in x else 1)


for ax, lab in zip(axes, labels):
    d = df[df['Label'] == lab].copy()

    # Scatter (geom_point)
    ax.scatter(d['Year'], d['Value'], s=20, color='black')

    # LOESS smoother (geom_smooth(method='loess', se=FALSE))
    # lowess expects sorted x
    d_sorted = d.sort_values('Year')
    sm = lowess(endog=d_sorted['Value'], exog=d_sorted['Year'], frac=0.3, it=0, return_sorted=True)
    ax.plot(sm[:, 0], sm[:, 1], color='royalblue', linewidth=2)

    # Panel (strip) title
    ax.set_title(lab, fontsize=14)

    # y-axis style
    ax.tick_params(labelsize=12)
    ax.set_ylabel("")   # axis.title blank like in your theme
    ax.grid(False)

# Common x settings: ticks every 5 years, rotated labels
xticks = np.arange(1980, 2020, 5)
axes[-1].set_xticks(xticks)
axes[-1].set_xticklabels(xticks, rotation=90, fontsize=12, color='black')
axes[-1].set_xlabel("")  # axis.title blank

# Overall title
CO2_temp_china_facet.suptitle("China Emissions and Temperatures (1980–2014)", fontsize=16, y=0.98)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

CO2_temp_china_facet

"""SPACE FOR ANALYSIS"""

# Convert 'Year' column to numeric before filtering
data_long['Year'] = pd.to_numeric(data_long['Year'], errors='coerce')

# Filter and pivot wider (like pivot_wider in R)
wide_china = (
    data_long[
        (data_long['Country'] == 'China') &
        (data_long['Year'] >= 1980) &
        (data_long['Year'] <= 2014)
    ]
    # remove Label column
    .drop(columns=['Label'])  # equivalent to select(-Label)
    .pivot(index='Year', columns='Indicator', values='Value')  # pivot_wider
    .reset_index()
)

# ---- Create scatter plot
plt.style.use('classic')
fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(
    wide_china['Emissions'],
    wide_china['Temperature'],
    color='black',
    s=30
)

# ---- Add linear regression line (equivalent to geom_smooth(method="lm"))
x = wide_china['Emissions']
y = wide_china['Temperature']
coef = np.polyfit(x, y, 1)  # degree 1 polynomial fit (linear)
poly1d_fn = np.poly1d(coef)
ax.plot(x, poly1d_fn(x), color='blue', linewidth=2)

# ---- Style like R theme()
ax.tick_params(axis='x', labelsize=9, colors='black')
ax.tick_params(axis='y', labelsize=9, colors='black')

ax.set_xlabel("Emissions (Metric Tonnes)", fontsize=14)
ax.set_ylabel("Temperature (Celcius)", fontsize=14)
ax.set_title("China Emissions and Temperature (1980-2014)", fontsize=16)

ax.grid(False)

plt.tight_layout()
plt.show()

china_temp_vs_emissions = fig

china_temp_vs_emissions

"""SPACE FOR ANALYSIS

# Individual Project Insights: Are CO2 emissions, temperature, and natural disasters in the United States associated?
"""

# ---- Filter to United States, 1980–2014, and the two indicators
US_facet_df = US_data_long.copy()
US_facet_df['Year'] = pd.to_numeric(US_facet_df['Year'], errors='coerce')

US_facet_df = US_facet_df[
    (US_facet_df['Country'] == 'United States') &
    (US_facet_df['Year'] >= 1980) & (US_facet_df['Year'] <= 2014) &
    (US_facet_df['Indicator'].isin(['Emissions', 'Temperature']))
].dropna(subset=['Year', 'Value']).sort_values('Year')

# Facet by 'Label' like facet_wrap(Label ~ ., ncol = 1, scales='free_y')
labels = list(US_facet_df['Label'].unique())
n = len(labels)

plt.style.use('classic')  # similar to theme_classic()
CO2_temp_US_facet, axes = plt.subplots(nrows=n, ncols=1, figsize=(10, 8), sharex=True)
if n == 1:
    axes = [axes]

labels = sorted(US_facet_df['Label'].unique(), key=lambda x: 0 if 'CO2' in x or 'Emissions' in x else 1)


for ax, lab in zip(axes, labels):
    US_d = US_facet_df[US_facet_df['Label'] == lab].copy()

    # Scatter (geom_point)
    ax.scatter(US_d['Year'], US_d['Value'], s=20, color='black')

    # LOESS smoother (geom_smooth(method='loess', se=FALSE))
    # lowess expects sorted x
    d_sorted = US_d.sort_values('Year')
    sm = lowess(endog=d_sorted['Value'], exog=d_sorted['Year'], frac=0.3, it=0, return_sorted=True)
    ax.plot(sm[:, 0], sm[:, 1], color='royalblue', linewidth=2)

    # Panel (strip) title
    ax.set_title(lab, fontsize=14)

    # y-axis style
    ax.tick_params(labelsize=12)
    ax.set_ylabel("")   # axis.title blank like in your theme
    ax.grid(False)

# Common x settings: ticks every 5 years, rotated labels
xticks = np.arange(1980, 2020, 5)
axes[-1].set_xticks(xticks)
axes[-1].set_xticklabels(xticks, rotation=90, fontsize=12, color='black')
axes[-1].set_xlabel("")  # axis.title blank

# Overall title
CO2_temp_US_facet.suptitle("United States Emissions and Temperatures (1980–2014)", fontsize=16, y=0.98)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

CO2_temp_US_facet

"""SPACE FOR ANALYSIS"""

# Convert 'Year' column to numeric before filtering
US_data_long['Year'] = pd.to_numeric(US_data_long['Year'], errors='coerce')

# Filter and pivot wider (like pivot_wider in R)
wide_US = (
    US_data_long[
        (US_data_long['Country'] == 'United States') &
        (US_data_long['Year'] >= 1980) &
        (US_data_long['Year'] <= 2014)
    ]
    # remove Label column
    .drop(columns=['Label'])  # equivalent to select(-Label)
    .pivot(index='Year', columns='Indicator', values='Value')  # pivot_wider
    .reset_index()
)

# ---- Create scatter plot
plt.style.use('classic')
fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(
    wide_US['Emissions'],
    wide_US['Temperature'],
    color='black',
    s=30
)

# ---- Add linear regression line (equivalent to geom_smooth(method="lm"))
x = wide_US['Emissions']
y = wide_US['Temperature']
coef = np.polyfit(x, y, 1)  # degree 1 polynomial fit (linear)
poly1d_fn = np.poly1d(coef)
ax.plot(x, poly1d_fn(x), color='blue', linewidth=2)

# ---- Style like R theme()
ax.tick_params(axis='x', labelsize=9, colors='black')
ax.tick_params(axis='y', labelsize=9, colors='black')

ax.set_xlabel("Emissions (Metric Tonnes)", fontsize=14)
ax.set_ylabel("Temperature (Celcius)", fontsize=14)
ax.set_title("United States Emissions and Temperature (1980-2014)", fontsize=16)

ax.grid(False)

plt.tight_layout()
plt.show()

US_temp_vs_emissions = fig

US_temp_vs_emissions

"""SPACE FOR ANALYSIS

### Group Project: Data Analysis

Calculate the Mean and SD for emissions and temperature for China
"""

# Calculate sample mean and standard deviation for CO2 emissions and temperature
emissions_temp_stats = wide_china.agg({
    "Emissions": ["mean", "std"],
    "Temperature": ["mean", "std"]
})

emissions_temp_stats

"""SPACE FOR ANALYSIS

Calculate the correlation coefficient for emissions and temperature
"""

# Calculate the correlation coefficient for emissions and temperature
r_temp = wide_china['Emissions'].corr(wide_china['Temperature'])
print(r_temp)

r_temp

"""SPACE FOR ANALYSIS
<br>
The calculated correlation coefficient for emissions and temperature is 0.546988116710011

Calculate the p_value for emissions and temperature
"""

# Calculate the correlation coefficient and confidence intervals
from scipy.stats import pearsonr

r, p_value_temp = pearsonr(wide_china['Emissions'], wide_china['Temperature'])

print(f"Pearson correlation: {r}")
print(f"P-value: {p_value_temp}")

p_value_temp

"""SPACE FOR ANALYSIS <br>
We see that the correlation coefficient quantifying the strength of the linear relationship between C02 emissions and temperature is statistically significant since the p-value is 0.0006734053713994809.

( Analyze this further + maybe describe why)
"""

import statsmodels.api as sm

# Standardize the variables similar to scale() in R
x = (wide_china['Emissions'] - wide_china['Emissions'].mean()) / wide_china['Emissions'].std()
y = (wide_china['Temperature'] - wide_china['Temperature'].mean()) / wide_china['Temperature'].std()

# Linear regression standardized so intercept of 0 and slope of p
X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

# Predicted values
y_pred = model.predict(X)

CO2_temp_china_scaled, ax = plt.subplots(figsize = (10, 6))

# Scatter plot
ax.scatter(x, y, color = 'black', alpha = 0.7)

# Regression line using new slope and intercept
ax.plot(x, y_pred, color = 'blue')
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

ax.set_title("China CO₂ Emissions and Temperature (1980–2014)")
ax.set_xlabel("Scaled Emissions (Metric Tonnes)", fontsize = 14)
ax.set_ylabel("Scaled Temperature (Celcius)", fontsize = 14)

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.show()

# Check that this figure is saved as CO2_temp_china_scaled
CO2_temp_china_scaled

"""SPACE FOR ANALYSIS

# Individual Project Insights: Data Analysis

Calculate the Mean and SD for emissions and temperature for the United States
"""

# Calculate sample mean and standard deviation for CO2 emissions and temperature
US_emissions_temp_stats = wide_US.agg({
    "Emissions": ["mean", "std"],
    "Temperature": ["mean", "std"]
})

US_emissions_temp_stats

"""SPACE FOR ANALYSIS

Calculate the correlation coefficient for emissions and temperature
"""

# Calculate the correlation coefficient for emissions and temperature
US_r_temp = wide_US['Emissions'].corr(wide_US['Temperature'])
print(US_r_temp)

"""SPACE FOR ANALYSIS
The calculated correlation coefficient for emissions and temperature is 0.4711717061539188

Calculate the p_value for emissions and temperature
"""

# Calculate the correlation coefficient and confidence intervals
from scipy.stats import pearsonr

r, US_p_value_temp = pearsonr(wide_US['Emissions'], wide_US['Temperature'])

print(f"Pearson correlation: {r}")
print(f"P-value: {US_p_value_temp}")

"""SPACE FOR ANALYSIS
We see that the correlation coefficient quantifying the strength of the linear relationship between C02 emissions and temperature is statistically significant since the p-value is 0.004277392732182289.

( Analyze this further + maybe describe why)
"""

import statsmodels.api as sm

# Standardize the variables similar to scale() in R
x = (wide_US['Emissions'] - wide_US['Emissions'].mean()) / wide_US['Emissions'].std()
y = (wide_US['Temperature'] - wide_US['Temperature'].mean()) / wide_US['Temperature'].std()

# Linear regression standardized so intercept of 0 and slope of p
X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

# Predicted values
y_pred = model.predict(X)

CO2_temp_US_scaled, ax = plt.subplots(figsize = (10, 6))

# Scatter plot
ax.scatter(x, y, color = 'black', alpha = 0.7)

# Regression line using new slope and intercept
ax.plot(x, y_pred, color = 'blue')
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

ax.set_title("United States CO₂ Emissions and Temperature (1980–2014)")
ax.set_xlabel("Scaled Emissions (Metric Tonnes)", fontsize = 14)
ax.set_ylabel("Scaled Temperature (Fahrenheit)", fontsize = 14)

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.show()

CO2_temp_US_scaled

"""SPACE FOR ANALYSIS

# Extra Credit

## Data Analysis Section for CO2 Emissions and Natural Disasters for China

#### **Calculate the Mean and SD for CO2 emissions and natural disasters for China**
"""

# Calculate sample mean and standard deviation for CO2 emissions and disasters
emissions_disasters_stats = wide_china.agg({
    "Emissions": ["mean", "std"],
    "Disasters": ["mean", "std"]
})

emissions_disasters_stats

"""#### **Calculate the correlation coefficient for emissions and disasters**"""

# Calculate the correlation coefficient for emissions and disasters
r = wide_china['Emissions'].corr(wide_china['Disasters'])
print(r)

"""Calculate the correlation coefficient for emissions and disasters:"""

r

"""(Our Analysis) The calculated correlation coefficient for emissions and disasters is 0.7472943463313393

Calculate the p_value for emissions and disasters:
"""

# Calculate the correlation coefficient and confidence intervals
from scipy.stats import pearsonr

r, p_value_disasters = pearsonr(wide_china['Emissions'], wide_china['Disasters'])

print(f"Pearson correlation: {r}")
print(f"P-value: {p_value_disasters}")

p_value_disasters

"""We see that the correlation coefficient quantifying the strength of the linear relationship between C02 emissions and disasters is statistically significant since the p-value is 2.5046711603242925e-07.

( Analyze this further + maybe describe why)


"""

import statsmodels.api as sm

# Standardize the variables similar to scale() in R
x = (wide_china['Emissions'] - wide_china['Emissions'].mean()) / wide_china['Emissions'].std()
y = (wide_china['Disasters'] - wide_china['Disasters'].mean()) / wide_china['Disasters'].std()

# Linear regression standardized so intercept of 0 and slope of p
X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

# Predicted values
y_pred = model.predict(X)

CO2_disaster_china_scaled, ax = plt.subplots(figsize = (10, 6))

# Scatter plot
ax.scatter(x, y, color = 'black', alpha = 0.7)

# Regression line using new slope and intercept
ax.plot(x, y_pred, color = 'blue')
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

ax.set_title("China CO₂ Emissions and Disasters (1980–2014)")
ax.set_xlabel("Scaled Emissions (Metric Tonnes)", fontsize = 14)
ax.set_ylabel("Scaled Disasters (Number of Disasters)", fontsize = 14)

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.show()

# Check that this plot is saved as CO2_disaster_china_scaled
CO2_disaster_china_scaled

"""SPACE FOR ANALYSIS

### Individual Project Insights: Data Analysis Section for CO2 Emissions and Natural Disasters for the United States

Calculate the Mean and SD for CO2 emissions and natural disasters for the United States
"""

# Calculate sample mean and standard deviation for CO2 emissions and disasters
US_emissions_disasters_stats = wide_US.agg({
    "Emissions": ["mean", "std"],
    "Disasters": ["mean", "std"]
})

US_emissions_disasters_stats

"""SPACE FOR ANALYSIS

Calculate the correlation coefficient for emissions and disasters for the United States
"""

# Calculate the correlation coefficient for emissions and disasters
US_r = wide_US['Emissions'].corr(wide_US['Disasters'])
print(US_r)

US_r

"""(Our Analysis) The calculated correlation coefficient for emissions and disasters is 0.3728168115515096

Calculate the p_value for emissions and disasters:
"""

# Calculate the correlation coefficient and confidence intervals
from scipy.stats import pearsonr

r, US_p_value_disasters = pearsonr(wide_US['Emissions'], wide_US['Disasters'])

print(f"Pearson correlation: {r}")
print(f"P-value: {US_p_value_disasters}")

"""We see that the correlation coefficient quantifying the strength of the linear relationship between C02 emissions and disasters is NOT??? statistically significant since the p-value is 0.027403701857556008.

( Analyze this further + maybe describe why)
"""

import statsmodels.api as sm

# Standardize the variables similar to scale() in R
x = (wide_US['Emissions'] - wide_US['Emissions'].mean()) / wide_US['Emissions'].std()
y = (wide_US['Disasters'] - wide_US['Disasters'].mean()) / wide_US['Disasters'].std()

# Linear regression standardized so intercept of 0 and slope of p
X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

# Predicted values
y_pred = model.predict(X)

CO2_disasters_US_scaled, ax = plt.subplots(figsize = (10, 6))

# Scatter plot
ax.scatter(x, y, color = 'black', alpha = 0.7)

# Regression line using new slope and intercept
ax.plot(x, y_pred, color = 'blue')
ax.grid(True, linestyle = '-', color = 'gray', alpha = 0.3)

ax.set_title("United States CO₂ Emissions and Disasters (1980–2014)")
ax.set_xlabel("Scaled Emissions (Metric Tonnes)", fontsize = 14)
ax.set_ylabel("Scaled Disasters (Number of Disasters)", fontsize = 14)

# Style matching the casestudy without spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.show()

CO2_disasters_US_scaled

"""SPACE FOR ANALYSIS

SPACE TO ANSWER THE MAIN RESEARCH QUESTIONS
"""

"""### Extra Credit Part 2: Bubble Plots of Top 10 Emitting Countries (Over Time)

"""

import geopandas as gpd

# -----------------------------
# Robust world geometry loader for GeoPandas 1.0+
# -----------------------------
world = None
try:
    # Natural Earth 110m countries (GeoJSON) – reliable public mirror
    ne_geojson = "https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/geojson/ne_110m_admin_0_countries.geojson"
    w = gpd.read_file(ne_geojson)

    # Helper: pick the first existing column from a list of candidates
    def pickcol(df, candidates):
        for c in candidates:
            if c in df.columns:
                return c
        raise KeyError(f"None of the candidate columns found: {candidates}")

    # Map various NE field names to a consistent schema
    name_col = pickcol(w, ["ADMIN", "NAME_LONG", "NAME_EN", "SOVEREIGNT", "NAME", "name"])
    iso3_col = pickcol(w, ["ADM0_A3", "ISO_A3", "iso_a3", "WB_A3"])
    cont_col = pickcol(w, ["CONTINENT", "continent"])

    world = w[[name_col, iso3_col, cont_col, "geometry"]].rename(
        columns={name_col: "ne_name", iso3_col: "iso_a3", cont_col: "continent"}
    )

    # Some NE rows use -99 or pseudo-codes; drop those for ISO merges
    world["iso_a3"] = world["iso_a3"].replace({"-99": pd.NA})
    print("Loaded world geometry from Natural Earth (GitHub GeoJSON).")
except Exception as e:
    print(f"Failed to load world geometry: {e}")
    world = None

# If still no world, stop gracefully
if world is None:
    print("Cannot proceed with the bubble map without world geometry data.")
else:
    # -----------------------------
    # Your existing emissions prep & plotting (unchanged)
    # -----------------------------
    if not {'Country','Indicator','Year','Value'}.issubset(set(globals().get('data_long', pd.DataFrame()).columns)):
        print("data_long is missing required columns: Country, Indicator, Year, Value.")
    else:
        data_long['Year'] = pd.to_numeric(data_long['Year'], errors='coerce')
        data_long_cleaned = data_long.dropna(subset=['Year', 'Value', 'Country']).copy()

        # Make the filter tolerant to case/whitespace; adjust keyword if needed
        emissions_mask = data_long_cleaned['Indicator'].astype(str).str.strip().str.lower().str.contains('emission', na=False)
        emissions_data = data_long_cleaned[emissions_mask]
        if emissions_data.empty:
            print("No emissions data found after cleaning. Cannot create bubble map.")
        else:
            latest_year_with_data = emissions_data['Year'].dropna().max()
            print(f"Latest year with emissions data: {int(latest_year_with_data) if pd.notna(latest_year_with_data) else latest_year_with_data}")

            emissions_latest_year = emissions_data[emissions_data['Year'] == latest_year_with_data].copy()
            if emissions_latest_year.empty:
                print(f"No emissions data found for year {latest_year_with_data}. Cannot create bubble map.")
            else:
                top_10_latest = emissions_latest_year.nlargest(10, 'Value').copy()
                if top_10_latest.empty:
                    print(f"Could not find top 10 emitting countries for {latest_year_with_data}.")
                else:
                    print("Top 10 emitting countries in the latest year:")
                    print(top_10_latest[['Country','Value']].to_string(index=False))

                    # Normalize names for name-join fallback
                    name_fixes = {
                        'United States': 'United States of America',
                        'USA': 'United States of America',
                        'US': 'United States of America',
                        'Russian Federation': 'Russia',
                        'Iran, Islamic Rep.': 'Iran',
                        'Venezuela, RB': 'Venezuela',
                        'Viet Nam': 'Vietnam',
                        'Czech Republic': 'Czechia',
                        'Korea, Rep.': 'South Korea',
                        'Korea, South': 'South Korea',
                        'Korea, Dem. People’s Rep.': 'North Korea',
                        'Egypt, Arab Rep.': 'Egypt',
                        'Gambia, The': 'The Gambia',
                        'Congo, Dem. Rep.': 'Democratic Republic of the Congo',
                        'Congo, Rep.': 'Republic of the Congo',
                        'Türkiye': 'Turkey',
                        'Bahamas, The': 'The Bahamas',
                        'Yemen, Rep.': 'Yemen',
                        'Bolivia (Plurinational State of)': 'Bolivia',
                        'Tanzania, United Republic of': 'Tanzania',
                        'Brunei Darussalam': 'Brunei',
                        'Lao PDR': 'Laos',
                    }
                    top_10_latest['Country_norm'] = top_10_latest['Country'].replace(name_fixes).str.strip()

                    # Prefer ISO3 merge if column exists and has any non-null values
                    use_iso = ('iso3' in top_10_latest.columns) and top_10_latest['iso3'].notna().any()
                    if use_iso:
                        m = top_10_latest.merge(world, left_on='iso3', right_on='iso_a3', how='left')
                        missing = m[m['geometry'].isna()].copy()
                        if not missing.empty:
                            fallback = (missing
                                        .drop(columns=[c for c in ['ne_name','iso_a3','continent','geometry'] if c in missing.columns])
                                        .merge(world, left_on='Country_norm', right_on='ne_name', how='left'))
                            for col in ['ne_name','iso_a3','continent','geometry']:
                                if col in m.columns and col in fallback.columns:
                                    m.loc[missing.index, col] = fallback[col].values
                    else:
                        m = top_10_latest.merge(world, left_on='Country_norm', right_on='ne_name', how='left')

                    unmatched = m[m['geometry'].isna()]
                    if not unmatched.empty:
                        cols = ['Country'] + (['iso3'] if 'iso3' in unmatched.columns else [])
                        print("⚠️ Unmatched countries (check names / ISO3):")
                        print(unmatched[cols].to_string(index=False))

                    gdf_top10 = gpd.GeoDataFrame(m.dropna(subset=['geometry']).copy(), geometry='geometry', crs=world.crs)
                    if gdf_top10.empty:
                        print("No countries matched with world map geometry. Cannot create bubble map.")
                    else:
                        rep_points = gdf_top10.representative_point()
                        gdf_top10['x'] = rep_points.x
                        gdf_top10['y'] = rep_points.y

                        print("Creating bubble map...")
                        fig, ax = plt.subplots(figsize=(15, 10))
                        world.plot(ax=ax, color='lightgray', linewidth=0)
                        world.boundary.plot(ax=ax, linewidth=0.5)

                        max_emissions = gdf_top10['Value'].max()
                        bubble_sizes = np.where(
                            (pd.isna(max_emissions) | (max_emissions == 0)),
                            50.0,
                            (gdf_top10['Value'] / max_emissions) * 2000.0
                        )

                        ax.scatter(
                            gdf_top10['x'], gdf_top10['y'],
                            s=bubble_sizes,
                            alpha=0.7,
                            edgecolors='black',
                            linewidth=0.8
                        )

                        for _, row in gdf_top10.iterrows():
                            ax.text(
                                row['x'], row['y'],
                                f"{row['Country']}\n{row['Value']:.0f}",
                                fontsize=9, ha='center', va='center'
                            )

                        ax.set_title(f"Top 10 CO₂ Emitting Countries in {int(latest_year_with_data)}", fontsize=16)
                        ax.set_axis_off()

                        # Legend bubbles (quantiles)
                        qvals = gdf_top10['Value'].quantile([0.25, 0.5, 0.75]).tolist()
                        handles = [plt.scatter([], [], s=(q / (max_emissions if max_emissions else 1)) * 2000.0,
                                               alpha=0.6, edgecolors='black', linewidth=0.8)
                                   for q in qvals]
                        labels = [f"{q:,.0f}" for q in qvals]
                        ax.legend(handles, labels, title="Emissions (metric tons)",
                                  loc='lower left', bbox_to_anchor=(0, 0), frameon=True)

                        plt.show()

                        bubble_plot = fig

bubble_plot

"""**Anoushka & Sofia's Analysis:** This bubble map displays the top 10 CO₂-emitting countries in 2014, with bubble size representing total emissions in metric tons. China is the clear leader, producing approximately 10.3 million metric tons, significantly surpassing all other countries. The United States ranks second with about 5.25 million metric tons, followed by India (2.24 million metric tons) and Russia (1.71 million metric tons). Other major contributors include Japan, Germany, Iran, Saudi Arabia, South Korea, and Canada, each with emissions between roughly 500,000 and 1.3 million metric tons.

The map highlights a concentration of high emissions in Asia, with China, India, Japan, South Korea, and Iran all ranking among the top emitters, reflecting the region’s industrial activity and large populations. North America also shows substantial emissions from the U.S. and Canada, while Europe’s representation comes from Germany and Russia (partially in Europe). Overall, the visualization emphasizes both the scale of China’s emissions compared to other nations and the global distribution of major emitters, underscoring the shared but uneven contributions to global CO₂ output.

China and the United States. China’s emissions, at roughly 10.3 million metric tons, are nearly double those of the United States, which stands at about 5.25 million metric tons. Geographically, this difference reflects China’s rapid industrialization, heavy reliance on coal, and manufacturing-driven economy, compared to the U.S.’s more mature industrial sector and ongoing transition toward cleaner energy sources. While both countries are economic powerhouses with large populations, China’s sheer scale of manufacturing for both domestic use and global export has driven its emissions far beyond the U.S. Despite the U.S. having one of the highest per capita emission rates globally, China’s total output dominates due to its vast industrial base and energy demands. This comparison underscores the challenge of global climate policy, as both nations’ emissions profiles are shaped by different economic structures, energy mixes, and stages of development.

"""


